{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLLtV6rOfQyh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from datetime import datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEdVd2hnVDAG"
      },
      "outputs": [],
      "source": [
        "file_csv = '../raw_data/merge_dfs.csv'\n",
        "df_raw_data = pd.read_csv(file_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pipeline_cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_data = pipeline_cleaning.clean_data(df_raw_data)\n",
        "clean_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list(clean_data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline_cleaning.transforming_data(clean_data)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_data['date'] = pd.to_datetime(clean_data['date'])\n",
        "clean_data.drop(columns=['jockey_id', 'tainer_id', 'margin', 'finish_position', 'event_number'], axis=1, inplace=True)\n",
        "clean_data.dropna(inplace=True) #instead of imputer\n",
        "df_train = clean_data[(clean_data['date'].dt.year != 2022) & (clean_data['date'].dt.year != 2023)]\n",
        "df_val = clean_data[clean_data['date'].dt.year == 2022]\n",
        "df_test = clean_data[clean_data['date'].dt.year == 2023]\n",
        "df_train.drop(columns=['date'], axis=1, inplace=True)\n",
        "df_val.drop(columns=['date'], axis=1, inplace=True)\n",
        "df_test.drop(columns=['date'], axis=1, inplace=True)\n",
        "\n",
        "categorical_col = ['barrier', 'track_condition', 'race_type', 'track_type',\n",
        "                    'race_class_normalised', 'race_class']\n",
        "num_col = ['distance', 'total_prize_money', 'jockey_allowance',\n",
        "            'handicap_weight', 'dslr', 'official rating', 'wfa',\n",
        "            'weight_adjustment', 'betfair_starting_price',\n",
        "            'pre_race_master_rating_int', 'starting_price', 'current_age']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[col for col in df_train.columns if col not in (num_col+categorical_col)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical_preprocessor = Pipeline([\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop='if_binary'))\n",
        "])\n",
        "numerical_preprocessor = Pipeline([\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "pipeline = ColumnTransformer([\n",
        "    ('categorical', categorical_preprocessor, categorical_col),\n",
        "    ('numerical', numerical_preprocessor, num_col)\n",
        "], remainder=\"passthrough\", sparse_threshold=0)\n",
        "pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline.fit(df_train)\n",
        "df_train_transformed = pipeline.transform(df_train)\n",
        "df_val_transformed = pipeline.transform(df_val)\n",
        "df_test_transformed = pipeline.transform(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline.transform(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pipeline.get_feature_names_out()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical_feature_names = pipeline.named_transformers_['categorical'].named_steps['onehot'].get_feature_names_out(input_features=categorical_col)\n",
        "\n",
        "# Obter os nomes das colunas numéricas\n",
        "numerical_feature_names = num_col\n",
        "remainder_col_names = [col for col in df_train.columns if col not in (num_col+categorical_col)]\n",
        "\n",
        "# Combinar os nomes das colunas categóricas e numéricas\n",
        "all_feature_names = list(categorical_feature_names) + numerical_feature_names + remainder_col_names\n",
        "all_feature_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test_transformed_with_columns = pd.DataFrame(df_test_transformed, columns=all_feature_names)\n",
        "df_val_transformed_with_columns = pd.DataFrame(df_val_transformed, columns=all_feature_names)\n",
        "df_train_transformed_with_columns = pd.DataFrame(df_train_transformed, columns=all_feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train_transformed_with_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
