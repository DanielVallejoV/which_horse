{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLLtV6rOfQyh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from datetime import datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEdVd2hnVDAG"
      },
      "outputs": [],
      "source": [
        "file_csv = '../raw_data/final_df.csv'\n",
        "df_raw_data = pd.read_csv(file_csv)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.drop(columns=['run_1_raw_post_race_rating_int', 'run_1_raw_post_race_rating_symbol', 'run_1_final_rating_int',\n",
        "            'run_1_race_type', 'run_1_race_class_normalised', 'run_1_race_class', 'run_1_track_type', 'run_1_win_lose',\n",
        "            'run_1_dsr', 'run_2_raw_post_race_rating_int', 'run_2_raw_post_race_rating_symbol', 'run_2_final_rating_int',\n",
        "            'run_2_race_type', 'run_2_race_class', 'run_2_race_class_normalised', 'run_2_track_type', 'run_2_win_lose',\n",
        "            'run_2_dsr', 'run_3_raw_post_race_rating_int', 'run_3_raw_post_race_rating_symbol', 'run_3_final_rating_int',\n",
        "            'run_3_race_type', 'run_3_race_class', 'run_3_race_class_normalised', 'run_3_track_type', 'run_3_win_lose',\n",
        "            'run_3_dsr', 'run_4_raw_post_race_rating_int', 'run_4_raw_post_race_rating_symbol', 'run_4_final_rating_int',\n",
        "            'run_4_race_type', 'run_4_race_class', 'run_4_race_class_normalised', 'run_4_track_type', 'run_4_win_lose',\n",
        "            'run_4_dsr', 'run_5_raw_post_race_rating_int', 'run_5_raw_post_race_rating_symbol', 'run_5_final_rating_int',\n",
        "            'run_5_race_type', 'run_5_race_class', 'run_5_race_class_normalised', 'run_5_track_type', 'run_5_win_lose',\n",
        "            'run_5_dsr', 'run_6_raw_post_race_rating_int', 'run_6_raw_post_race_rating_symbol', 'run_6_final_rating_int',\n",
        "            'run_6_race_type', 'run_6_race_class', 'run_6_race_class_normalised', 'run_6_track_type', 'run_6_win_lose',\n",
        "            'run_6_dsr', 'run_7_raw_post_race_rating_int', 'run_7_raw_post_race_rating_symbol', 'run_7_final_rating_int',\n",
        "            'run_7_race_type', 'run_7_race_class', 'run_7_race_class_normalised', 'run_7_track_type', 'run_7_win_lose',\n",
        "            'run_7_dsr', 'run_8_raw_post_race_rating_int', 'run_8_raw_post_race_rating_symbol', 'run_8_final_rating_int',\n",
        "            'run_8_race_type', 'run_8_race_class', 'run_8_race_class_normalised', 'run_8_track_type', 'run_8_win_lose',\n",
        "            'run_8_dsr', 'meeting_name', 'country_code', 'distance_unit','distance_furlongs', 'prize_money_currency',\n",
        "            'jockey_allowance_unit', 'handicap_weight_unit', 'jockey_name', 'trainer_name',\n",
        "            'pre_race_master_rating_symbol', 'post_race_master_rating_symbol', 'post_race_master_rating_int',\n",
        "            'bet365_odds', 'pmu_odds', 'meeting_id', 'distance_raw_furlongs', 'number', 'horse_id',  'dam', 'sire',\n",
        "            'Date', 'id_lewagon'], inplace=True)\n",
        "df['gear'] = df['gear'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
        "df['rating_oficial'] = df['OffR'].fillna(df['official rating'])\n",
        "df['rating_oficial'] = df['official rating'].fillna(df['OffR'])\n",
        "df['finish_position'].fillna(df['Place'], inplace=True)\n",
        "\n",
        "df = df[df['barrier'] <= 20]\n",
        "df['failed_to_finish_reason'] = df['failed_to_finish_reason'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
        "df['margin'] = df.apply(lambda row: row['distance'] if pd.isna(row['margin']) and (row['win_or_lose'] == 1 or row['failed_to_finish_reason'] == 1) else row['margin'], axis=1)\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df['birth_date'] = pd.to_datetime(df['birth_date'])\n",
        "df['current_age'] = (((df['date'] - df['birth_date']).dt.days ) ).astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sorted = df.sort_values(by=['horse_name', 'date'])\n",
        "df_sorted[['date', 'horse_name', 'dslr']].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sorted[['date', 'horse_name', 'dslr']].groupby('horse_name').agg({'date': 'diff'}).isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sorted['dslr'] = df_sorted['dslr'].fillna(df_sorted.groupby('horse_name')['date'].diff().dt.days)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sorted[['date', 'horse_name', 'dslr', 'current_age', 'age']][df_sorted.dslr.isna()].age.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pipeline_cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_data = pipeline_cleaning.clean_data(df_raw_data)\n",
        "clean_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_data['date'] = pd.to_datetime(clean_data['date'])\n",
        "clean_data.drop(columns=['tainer_id', 'margin', 'dslr','rating_oficial',\n",
        "                    'last_traded_price', 'finish_position', 'event_number',\n",
        "                    'pre_race_master_rating_int',\n",
        "                    'post_time'], axis=1, inplace=True)# for now\n",
        "clean_data.dropna(inplace=True) #instead of imputer for now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_grouped = clean_data.groupby(by=['jockey_id']).agg({'win_or_lose': 'sum'}).sort_values(by='win_or_lose', ascending=False)\n",
        "df_grouped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "quantiles = df_grouped['win_or_lose'].quantile([0.2, 0.4, 0.6, 0.8])\n",
        "\n",
        "# Classify jockey_id into 5 groups based on the number of wins\n",
        "def classify_group(win_or_lose):\n",
        "    if win_or_lose <= quantiles[0.2]:\n",
        "        return 1\n",
        "    elif win_or_lose <= quantiles[0.4]:\n",
        "        return 2\n",
        "    elif win_or_lose <= quantiles[0.6]:\n",
        "        return 3\n",
        "    elif win_or_lose <= quantiles[0.8]:\n",
        "        return 4\n",
        "    else:\n",
        "        return 5\n",
        "\n",
        "df_grouped['win_or_lose_class'] = df_grouped['win_or_lose'].apply(classify_group)\n",
        "df_grouped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(clean_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_data.merge(df_grouped, how='left', left_on='jockey_id', right_on='jockey_id')\n",
        "clean_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "colunas = ['15_mins', '10_mins', '5_mins', '3_mins', '2_mins', '1_min_']\n",
        "\n",
        "df_sem_nan = clean_data.dropna(subset=colunas, how='all')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(df_sem_nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "media_valores = df_sem_nan[colunas].mean(axis=1)\n",
        "\n",
        "for coluna in colunas:\n",
        "    df_sem_nan[coluna].fillna(media_valores, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sem_nan.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "number_of_nas = df_sem_nan[['15_mins', '10_mins', '5_mins', '3_mins', '2_mins', '1_min_']].isna().sum().sum()\n",
        "while number_of_nas > 0:\n",
        "    df_sem_nan['1_min_'] = df_sem_nan['1_min_'].fillna(df_sem_nan['2_mins'])\n",
        "    df_sem_nan['2_mins'] = df_sem_nan['2_mins'].fillna(df_sem_nan['3_mins'])\n",
        "    df_sem_nan['3_mins'] = df_sem_nan['3_mins'].fillna(df_sem_nan['5_mins'])\n",
        "    df_sem_nan['5_mins'] = df_sem_nan['5_mins'].fillna(df_sem_nan['10_mins'])\n",
        "    df_sem_nan['10_mins'] = df_sem_nan['10_mins'].fillna(df_sem_nan['15_mins'])\n",
        "\n",
        "    df_sem_nan['15_mins'] = df_sem_nan['15_mins'].fillna(df_sem_nan['10_mins'])\n",
        "    df_sem_nan['10_mins'] = df_sem_nan['10_mins'].fillna(df_sem_nan['5_mins'])\n",
        "    df_sem_nan['5_mins'] = df_sem_nan['5_mins'].fillna(df_sem_nan['3_mins'])\n",
        "    df_sem_nan['3_mins'] = df_sem_nan['3_mins'].fillna(df_sem_nan['2_mins'])\n",
        "    df_sem_nan['2_mins'] = df_sem_nan['2_mins'].fillna(df_sem_nan['1_min_'])\n",
        "    number_of_nas = df_sem_nan[['15_mins', '10_mins', '5_mins', '3_mins', '2_mins', '1_min_']].isna().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sem_nan.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sem_nan.to_csv('../raw_data/withoutna.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "jockey_class = pipeline_cleaning.transforming_data(clean_data, jockey_id=True)[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "jockey_class.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_data['date'] = pd.to_datetime(clean_data['date'])\n",
        "clean_data.drop(columns=['jockey_id', 'tainer_id', 'margin', 'finish_position', 'event_number'], axis=1, inplace=True)\n",
        "clean_data.dropna(inplace=True) #instead of imputer\n",
        "df_train = clean_data[(clean_data['date'].dt.year != 2022) & (clean_data['date'].dt.year != 2023)]\n",
        "df_val = clean_data[clean_data['date'].dt.year == 2022]\n",
        "df_test = clean_data[clean_data['date'].dt.year == 2023]\n",
        "df_train.drop(columns=['date'], axis=1, inplace=True)\n",
        "df_val.drop(columns=['date'], axis=1, inplace=True)\n",
        "df_test.drop(columns=['date'], axis=1, inplace=True)\n",
        "\n",
        "categorical_col = ['barrier', 'track_condition', 'race_type', 'track_type',\n",
        "                    'race_class_normalised', 'race_class']\n",
        "num_col = ['distance', 'total_prize_money', 'jockey_allowance',\n",
        "            'handicap_weight', 'dslr', 'official rating', 'wfa',\n",
        "            'weight_adjustment', 'betfair_starting_price',\n",
        "            'pre_race_master_rating_int', 'starting_price', 'current_age']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[col for col in df_train.columns if col not in (num_col+categorical_col)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical_preprocessor = Pipeline([\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop='if_binary'))\n",
        "])\n",
        "numerical_preprocessor = Pipeline([\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "pipeline = ColumnTransformer([\n",
        "    ('categorical', categorical_preprocessor, categorical_col),\n",
        "    ('numerical', numerical_preprocessor, num_col)\n",
        "], remainder=\"passthrough\", sparse_threshold=0)\n",
        "pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline.fit(df_train)\n",
        "df_train_transformed = pipeline.transform(df_train)\n",
        "df_val_transformed = pipeline.transform(df_val)\n",
        "df_test_transformed = pipeline.transform(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline.transform(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pipeline.get_feature_names_out()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical_feature_names = pipeline.named_transformers_['categorical'].named_steps['onehot'].get_feature_names_out(input_features=categorical_col)\n",
        "\n",
        "# Obter os nomes das colunas numéricas\n",
        "numerical_feature_names = num_col\n",
        "remainder_col_names = [col for col in df_train.columns if col not in (num_col+categorical_col)]\n",
        "\n",
        "# Combinar os nomes das colunas categóricas e numéricas\n",
        "all_feature_names = list(categorical_feature_names) + numerical_feature_names + remainder_col_names\n",
        "all_feature_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test_transformed_with_columns = pd.DataFrame(df_test_transformed, columns=all_feature_names)\n",
        "df_val_transformed_with_columns = pd.DataFrame(df_val_transformed, columns=all_feature_names)\n",
        "df_train_transformed_with_columns = pd.DataFrame(df_train_transformed, columns=all_feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train_transformed_with_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
