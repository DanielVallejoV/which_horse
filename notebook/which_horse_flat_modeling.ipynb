{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_csv = '/Users/jubba/Downloads/Which_Horse_Concat.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/7l27jzt92cs7ljtj5xn5sd3h0000gn/T/ipykernel_13246/3708549570.py:2: DtypeWarning: Columns (9,22,53,80) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_raw_data = pd.read_csv('/Users/jubba/which_horse/raw_data/combined_flat_csv.csv')\n",
      "/Users/jubba/which_horse/notebook/pipeline_cleaning.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['failed_to_finish_reason'] = df['failed_to_finish_reason'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
      "/Users/jubba/which_horse/notebook/pipeline_cleaning.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['margin'] = df.apply(lambda row: row['distance'] if pd.isna(row['margin']) and (row['win_or_lose'] == 1 or row['failed_to_finish_reason'] == 1) else row['margin'], axis=1)\n",
      "/Users/jubba/which_horse/notebook/pipeline_cleaning.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date'] = pd.to_datetime(df['date'])\n",
      "/Users/jubba/which_horse/notebook/pipeline_cleaning.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['birth_date'] = pd.to_datetime(df['birth_date'])\n",
      "/Users/jubba/which_horse/notebook/pipeline_cleaning.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['current_age'] = (((df['date'] - df['birth_date']).dt.days % 365) // 30).astype(float)\n",
      "/Users/jubba/which_horse/notebook/pipeline_cleaning.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=['failed_to_finish_reason', 'birth_date'], inplace=True)\n",
      "/Users/jubba/which_horse/notebook/pipeline_cleaning.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date'] = pd.to_datetime(df['date'])\n",
      "/Users/jubba/which_horse/notebook/pipeline_cleaning.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=['jockey_id', 'tainer_id', 'margin', 'finish_position', 'event_number'], axis=1, inplace=True) # for now\n",
      "/Users/jubba/which_horse/notebook/pipeline_cleaning.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(inplace=True) #instead of imputer for now\n",
      "/Users/jubba/which_horse/notebook/pipeline_cleaning.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(columns=['date'], axis=1, inplace=True)\n",
      "/Users/jubba/which_horse/notebook/pipeline_cleaning.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val.drop(columns=['date'], axis=1, inplace=True)\n",
      "/Users/jubba/which_horse/notebook/pipeline_cleaning.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(columns=['date'], axis=1, inplace=True)\n",
      "/Users/jubba/.pyenv/versions/3.10.6/envs/which_horse/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:241: UserWarning: Found unknown categories in columns [5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/jubba/.pyenv/versions/3.10.6/envs/which_horse/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:241: UserWarning: Found unknown categories in columns [5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pipeline_cleaning import clean_data, transforming_data\n",
    "df_raw_data = pd.read_csv('/Users/jubba/which_horse/raw_data/combined_flat_csv.csv')\n",
    "df_cleaned = clean_data(df_raw_data)\n",
    "df_transformed_train, df_transformed_val, df_transformed_test = transforming_data(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barrier_1</th>\n",
       "      <th>barrier_2</th>\n",
       "      <th>barrier_3</th>\n",
       "      <th>barrier_4</th>\n",
       "      <th>barrier_5</th>\n",
       "      <th>barrier_6</th>\n",
       "      <th>barrier_7</th>\n",
       "      <th>barrier_8</th>\n",
       "      <th>barrier_9</th>\n",
       "      <th>barrier_10</th>\n",
       "      <th>...</th>\n",
       "      <th>dslr</th>\n",
       "      <th>official rating</th>\n",
       "      <th>wfa</th>\n",
       "      <th>weight_adjustment</th>\n",
       "      <th>betfair_starting_price</th>\n",
       "      <th>pre_race_master_rating_int</th>\n",
       "      <th>starting_price</th>\n",
       "      <th>current_age</th>\n",
       "      <th>win_or_lose</th>\n",
       "      <th>gear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626061</td>\n",
       "      <td>1.216325</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>-0.902431</td>\n",
       "      <td>-0.248341</td>\n",
       "      <td>0.141816</td>\n",
       "      <td>-0.279505</td>\n",
       "      <td>-0.685620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.422518</td>\n",
       "      <td>0.898229</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>-1.409811</td>\n",
       "      <td>-0.147846</td>\n",
       "      <td>0.513970</td>\n",
       "      <td>-0.122437</td>\n",
       "      <td>-1.275833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.736533</td>\n",
       "      <td>0.739181</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>-1.029276</td>\n",
       "      <td>-0.347054</td>\n",
       "      <td>0.281374</td>\n",
       "      <td>-0.548764</td>\n",
       "      <td>-0.390514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.108502</td>\n",
       "      <td>0.686165</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>-0.902431</td>\n",
       "      <td>-0.291092</td>\n",
       "      <td>0.607008</td>\n",
       "      <td>-0.414135</td>\n",
       "      <td>-0.685620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626061</td>\n",
       "      <td>0.527118</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>-0.521896</td>\n",
       "      <td>-0.343800</td>\n",
       "      <td>0.653527</td>\n",
       "      <td>-0.548764</td>\n",
       "      <td>-1.275833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51115</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.641015</td>\n",
       "      <td>-1.275424</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>1.000244</td>\n",
       "      <td>0.049499</td>\n",
       "      <td>-0.462933</td>\n",
       "      <td>0.595586</td>\n",
       "      <td>-0.095407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51116</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.551296</td>\n",
       "      <td>-1.328440</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>1.127089</td>\n",
       "      <td>-0.216961</td>\n",
       "      <td>-0.323376</td>\n",
       "      <td>-0.279505</td>\n",
       "      <td>0.199699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51117</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.551296</td>\n",
       "      <td>-1.699552</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>2.015004</td>\n",
       "      <td>-0.088428</td>\n",
       "      <td>-0.881606</td>\n",
       "      <td>0.057068</td>\n",
       "      <td>0.494805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51118</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.521390</td>\n",
       "      <td>-1.805583</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>1.761314</td>\n",
       "      <td>0.124624</td>\n",
       "      <td>-0.462933</td>\n",
       "      <td>0.460957</td>\n",
       "      <td>0.789912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51119</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.401764</td>\n",
       "      <td>-0.374153</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>-1.156121</td>\n",
       "      <td>-0.341284</td>\n",
       "      <td>-0.416414</td>\n",
       "      <td>-0.526326</td>\n",
       "      <td>0.494805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51120 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       barrier_1  barrier_2  barrier_3  barrier_4  barrier_5  barrier_6  \\\n",
       "0            0.0        0.0        1.0        0.0        0.0        0.0   \n",
       "1            0.0        1.0        0.0        0.0        0.0        0.0   \n",
       "2            0.0        0.0        0.0        1.0        0.0        0.0   \n",
       "3            0.0        0.0        0.0        0.0        1.0        0.0   \n",
       "4            0.0        0.0        0.0        0.0        0.0        1.0   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "51115        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "51116        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "51117        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "51118        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "51119        0.0        1.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "       barrier_7  barrier_8  barrier_9  barrier_10  ...      dslr  \\\n",
       "0            0.0        0.0        0.0         0.0  ... -0.626061   \n",
       "1            0.0        0.0        0.0         0.0  ...  1.422518   \n",
       "2            0.0        0.0        0.0         0.0  ...  1.736533   \n",
       "3            0.0        0.0        0.0         0.0  ...  1.108502   \n",
       "4            0.0        0.0        0.0         0.0  ... -0.626061   \n",
       "...          ...        ...        ...         ...  ...       ...   \n",
       "51115        0.0        1.0        0.0         0.0  ... -0.641015   \n",
       "51116        0.0        0.0        1.0         0.0  ... -0.551296   \n",
       "51117        0.0        0.0        0.0         0.0  ... -0.551296   \n",
       "51118        0.0        0.0        0.0         0.0  ... -0.521390   \n",
       "51119        0.0        0.0        0.0         0.0  ... -0.401764   \n",
       "\n",
       "       official rating       wfa  weight_adjustment  betfair_starting_price  \\\n",
       "0             1.216325 -0.125193          -0.902431               -0.248341   \n",
       "1             0.898229 -0.125193          -1.409811               -0.147846   \n",
       "2             0.739181 -0.125193          -1.029276               -0.347054   \n",
       "3             0.686165 -0.125193          -0.902431               -0.291092   \n",
       "4             0.527118 -0.125193          -0.521896               -0.343800   \n",
       "...                ...       ...                ...                     ...   \n",
       "51115        -1.275424 -0.125193           1.000244                0.049499   \n",
       "51116        -1.328440 -0.125193           1.127089               -0.216961   \n",
       "51117        -1.699552 -0.125193           2.015004               -0.088428   \n",
       "51118        -1.805583 -0.125193           1.761314                0.124624   \n",
       "51119        -0.374153 -0.125193          -1.156121               -0.341284   \n",
       "\n",
       "       pre_race_master_rating_int  starting_price  current_age  win_or_lose  \\\n",
       "0                        0.141816       -0.279505    -0.685620          0.0   \n",
       "1                        0.513970       -0.122437    -1.275833          0.0   \n",
       "2                        0.281374       -0.548764    -0.390514          0.0   \n",
       "3                        0.607008       -0.414135    -0.685620          0.0   \n",
       "4                        0.653527       -0.548764    -1.275833          0.0   \n",
       "...                           ...             ...          ...          ...   \n",
       "51115                   -0.462933        0.595586    -0.095407          0.0   \n",
       "51116                   -0.323376       -0.279505     0.199699          0.0   \n",
       "51117                   -0.881606        0.057068     0.494805          0.0   \n",
       "51118                   -0.462933        0.460957     0.789912          0.0   \n",
       "51119                   -0.416414       -0.526326     0.494805          0.0   \n",
       "\n",
       "       gear  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "...     ...  \n",
       "51115   0.0  \n",
       "51116   1.0  \n",
       "51117   0.0  \n",
       "51118   0.0  \n",
       "51119   1.0  \n",
       "\n",
       "[51120 rows x 59 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifcation X and Y\n",
    "#X = df.drop(columns=['win_or_lose', 'date', 'birth_date', 'finish_position', 'failed_to_finish_reason'])\n",
    "#y = df['win_or_lose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression X and Y\n",
    "X = df.drop(columns=['betfair_starting_price', 'date', 'birth_date'])\n",
    "y = df['betfair_starting_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #temporary drop, values will be imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['margin'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[X.isna().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(X.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.replace({0.5 : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_1 = df['win_or_lose'] == 1\n",
    "print(mask_1.sum())\n",
    "mask_0 = df['win_or_lose'] == 0\n",
    "print(mask_0.sum())\n",
    "wins = 23087\n",
    "loses = 184016\n",
    "print(wins / (wins+loses) * 100)\n",
    "print(loses / (wins+loses) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler # cant be used as too much data is loss\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207214,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jubba/.pyenv/versions/3.10.6/envs/which_horse/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py:363: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42, k_neighbors=5, sampling_strategy=1, n_jobs=-1)\n",
    "X_res, y_res = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183293\n",
      "183293\n"
     ]
    }
   ],
   "source": [
    "mask_win_synthetic = y_res == 1\n",
    "print(mask_win_synthetic.sum())\n",
    "mask_lose_synthetic = y_res == 0\n",
    "print(mask_lose_synthetic.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['meeting_id', 'date', 'event_number', 'distance',\n",
       "       'distance_raw_furlongs', 'total_prize_money', 'track_type', 'barrier',\n",
       "       'number', 'finish_position', 'win_or_lose', 'failed_to_finish_reason',\n",
       "       'margin', 'gear', 'jockey_allowance', 'handicap_weight', 'jockey_id',\n",
       "       'tainer_id', 'dslr', 'horse_id', 'age', 'birth_date', 'official rating',\n",
       "       'wfa', 'weight_adjustment', 'pre_race_master_rating_int',\n",
       "       'starting_price', 'track_condition_FAST', 'track_condition_FIRM',\n",
       "       'track_condition_GOOD', 'track_condition_GOOD TO FIRM',\n",
       "       'track_condition_GOOD TO SOFT', 'track_condition_GOOD TO YIELDING',\n",
       "       'track_condition_HEAVY', 'track_condition_SLOW', 'track_condition_SOFT',\n",
       "       'track_condition_STANDARD', 'track_condition_STANDARD TO FAST',\n",
       "       'track_condition_STANDARD TO SLOW', 'race_type_FLAT',\n",
       "       'race_type_NATIONAL_HUNT_FLAT', 'race_class_1', 'race_class_2',\n",
       "       'race_class_3', 'race_class_4', 'race_class_5', 'race_class_6',\n",
       "       'race_class_7', 'race_class_normalised_Claiming',\n",
       "       'race_class_normalised_Conditions', 'race_class_normalised_Grade 1',\n",
       "       'race_class_normalised_Grade 2', 'race_class_normalised_Group 1',\n",
       "       'race_class_normalised_Group 2', 'race_class_normalised_Group 3',\n",
       "       'race_class_normalised_Handicap', 'race_class_normalised_Listed',\n",
       "       'race_class_normalised_Maiden', 'race_class_normalised_NHF',\n",
       "       'race_class_normalised_Novice', 'race_class_normalised_Selling',\n",
       "       'race_class_normalised_nan', 'life_days', 'current_age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_transformed_train.drop(columns=['betfair_starting_price'])\n",
    "X_test = df_transformed_test.drop(columns=['betfair_starting_price'])\n",
    "y_train = df_transformed_train['betfair_starting_price']\n",
    "y_test = df_transformed_test['betfair_starting_price']\n",
    "#X_val = df_transformed_val[]\n",
    "#y_val = df_transformed_val[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgbclassifierwere going to use becausewhethera horse loses or wins is biunary classificatiojn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51120, 58), (12194, 58), (51120,), (12194,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(\n",
    "    tree_method='hist',\n",
    "    booster='gbtree',\n",
    "    objective='reg:logistic',\n",
    "    random_state=42,\n",
    "    learning_rate=0.001,\n",
    "    colsample_bytree=0.9,\n",
    "    n_estimators=110,\n",
    "    subsample=0.75\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import get_custom_objects\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barrier_1</th>\n",
       "      <th>barrier_2</th>\n",
       "      <th>barrier_3</th>\n",
       "      <th>barrier_4</th>\n",
       "      <th>barrier_5</th>\n",
       "      <th>barrier_6</th>\n",
       "      <th>barrier_7</th>\n",
       "      <th>barrier_8</th>\n",
       "      <th>barrier_9</th>\n",
       "      <th>barrier_10</th>\n",
       "      <th>...</th>\n",
       "      <th>handicap_weight</th>\n",
       "      <th>dslr</th>\n",
       "      <th>official rating</th>\n",
       "      <th>wfa</th>\n",
       "      <th>weight_adjustment</th>\n",
       "      <th>pre_race_master_rating_int</th>\n",
       "      <th>starting_price</th>\n",
       "      <th>current_age</th>\n",
       "      <th>win_or_lose</th>\n",
       "      <th>gear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902431</td>\n",
       "      <td>-0.626061</td>\n",
       "      <td>1.216325</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>-0.902431</td>\n",
       "      <td>0.141816</td>\n",
       "      <td>-0.279505</td>\n",
       "      <td>-0.685620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.409811</td>\n",
       "      <td>1.422518</td>\n",
       "      <td>0.898229</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>-1.409811</td>\n",
       "      <td>0.513970</td>\n",
       "      <td>-0.122437</td>\n",
       "      <td>-1.275833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.029276</td>\n",
       "      <td>1.736533</td>\n",
       "      <td>0.739181</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>-1.029276</td>\n",
       "      <td>0.281374</td>\n",
       "      <td>-0.548764</td>\n",
       "      <td>-0.390514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902431</td>\n",
       "      <td>1.108502</td>\n",
       "      <td>0.686165</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>-0.902431</td>\n",
       "      <td>0.607008</td>\n",
       "      <td>-0.414135</td>\n",
       "      <td>-0.685620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521896</td>\n",
       "      <td>-0.626061</td>\n",
       "      <td>0.527118</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>-0.521896</td>\n",
       "      <td>0.653527</td>\n",
       "      <td>-0.548764</td>\n",
       "      <td>-1.275833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51115</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000244</td>\n",
       "      <td>-0.641015</td>\n",
       "      <td>-1.275424</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>1.000244</td>\n",
       "      <td>-0.462933</td>\n",
       "      <td>0.595586</td>\n",
       "      <td>-0.095407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51116</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.127089</td>\n",
       "      <td>-0.551296</td>\n",
       "      <td>-1.328440</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>1.127089</td>\n",
       "      <td>-0.323376</td>\n",
       "      <td>-0.279505</td>\n",
       "      <td>0.199699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51117</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.015004</td>\n",
       "      <td>-0.551296</td>\n",
       "      <td>-1.699552</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>2.015004</td>\n",
       "      <td>-0.881606</td>\n",
       "      <td>0.057068</td>\n",
       "      <td>0.494805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51118</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.761314</td>\n",
       "      <td>-0.521390</td>\n",
       "      <td>-1.805583</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>1.761314</td>\n",
       "      <td>-0.462933</td>\n",
       "      <td>0.460957</td>\n",
       "      <td>0.789912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51119</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.156121</td>\n",
       "      <td>-0.401764</td>\n",
       "      <td>-0.374153</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>-1.156121</td>\n",
       "      <td>-0.416414</td>\n",
       "      <td>-0.526326</td>\n",
       "      <td>0.494805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51120 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       barrier_1  barrier_2  barrier_3  barrier_4  barrier_5  barrier_6  \\\n",
       "0            0.0        0.0        1.0        0.0        0.0        0.0   \n",
       "1            0.0        1.0        0.0        0.0        0.0        0.0   \n",
       "2            0.0        0.0        0.0        1.0        0.0        0.0   \n",
       "3            0.0        0.0        0.0        0.0        1.0        0.0   \n",
       "4            0.0        0.0        0.0        0.0        0.0        1.0   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "51115        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "51116        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "51117        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "51118        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "51119        0.0        1.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "       barrier_7  barrier_8  barrier_9  barrier_10  ...  handicap_weight  \\\n",
       "0            0.0        0.0        0.0         0.0  ...         0.902431   \n",
       "1            0.0        0.0        0.0         0.0  ...         1.409811   \n",
       "2            0.0        0.0        0.0         0.0  ...         1.029276   \n",
       "3            0.0        0.0        0.0         0.0  ...         0.902431   \n",
       "4            0.0        0.0        0.0         0.0  ...         0.521896   \n",
       "...          ...        ...        ...         ...  ...              ...   \n",
       "51115        0.0        1.0        0.0         0.0  ...        -1.000244   \n",
       "51116        0.0        0.0        1.0         0.0  ...        -1.127089   \n",
       "51117        0.0        0.0        0.0         0.0  ...        -2.015004   \n",
       "51118        0.0        0.0        0.0         0.0  ...        -1.761314   \n",
       "51119        0.0        0.0        0.0         0.0  ...         1.156121   \n",
       "\n",
       "           dslr  official rating       wfa  weight_adjustment  \\\n",
       "0     -0.626061         1.216325 -0.125193          -0.902431   \n",
       "1      1.422518         0.898229 -0.125193          -1.409811   \n",
       "2      1.736533         0.739181 -0.125193          -1.029276   \n",
       "3      1.108502         0.686165 -0.125193          -0.902431   \n",
       "4     -0.626061         0.527118 -0.125193          -0.521896   \n",
       "...         ...              ...       ...                ...   \n",
       "51115 -0.641015        -1.275424 -0.125193           1.000244   \n",
       "51116 -0.551296        -1.328440 -0.125193           1.127089   \n",
       "51117 -0.551296        -1.699552 -0.125193           2.015004   \n",
       "51118 -0.521390        -1.805583 -0.125193           1.761314   \n",
       "51119 -0.401764        -0.374153 -0.125193          -1.156121   \n",
       "\n",
       "       pre_race_master_rating_int  starting_price  current_age  win_or_lose  \\\n",
       "0                        0.141816       -0.279505    -0.685620          0.0   \n",
       "1                        0.513970       -0.122437    -1.275833          0.0   \n",
       "2                        0.281374       -0.548764    -0.390514          0.0   \n",
       "3                        0.607008       -0.414135    -0.685620          0.0   \n",
       "4                        0.653527       -0.548764    -1.275833          0.0   \n",
       "...                           ...             ...          ...          ...   \n",
       "51115                   -0.462933        0.595586    -0.095407          0.0   \n",
       "51116                   -0.323376       -0.279505     0.199699          0.0   \n",
       "51117                   -0.881606        0.057068     0.494805          0.0   \n",
       "51118                   -0.462933        0.460957     0.789912          0.0   \n",
       "51119                   -0.416414       -0.526326     0.494805          0.0   \n",
       "\n",
       "       gear  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "...     ...  \n",
       "51115   0.0  \n",
       "51116   1.0  \n",
       "51117   0.0  \n",
       "51118   0.0  \n",
       "51119   1.0  \n",
       "\n",
       "[51120 rows x 58 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       -0.248341\n",
       "1       -0.147846\n",
       "2       -0.347054\n",
       "3       -0.291092\n",
       "4       -0.343800\n",
       "           ...   \n",
       "51115    0.049499\n",
       "51116   -0.216961\n",
       "51117   -0.088428\n",
       "51118    0.124624\n",
       "51119   -0.341284\n",
       "Name: betfair_starting_price, Length: 51120, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_loss_function(y_pred, y_true):\n",
    "\n",
    "\n",
    "    # win_horse = y_true[:, 0]\n",
    "    # win_odds = y_true[:, 1]\n",
    "    # gain_loss_vector = win_horse * (win_odds - 1) + (1 - win_horse) * -1\n",
    "    # y_true = y_true.reshape(-1,1)\n",
    "    # return -0.1 * y_true * y_pred\n",
    "    # return -0.1 * np.mean(np.sum(y_true * y_pred))\n",
    "    #return -1 * tf.reduce_mean(tf.reduce_sum(gain_loss_vector * y_pred, axis=1))\n",
    "    # gain_loss_vector = K.concatenate([win_horse * (win_odds - 1) + (1 - win_horse) * -1, -> profit or loss of winning/losing on a bet of £1\n",
    "    # K.zeros_like(win_odds)], axis=1) -> this is padding as y_true is longer then y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_function(y_true, y_pred):\n",
    "  \"\"\"Custom loss function for XGBoost with gradient and hessian.\n",
    "\n",
    "  Args:\n",
    "      y_true: Ground truth labels (numpy array).\n",
    "      y_pred: Predicted values by the model (numpy array).\n",
    "\n",
    "  Returns:\n",
    "      grad: A numpy array of gradients for each data point.\n",
    "      hess: A numpy array of hessians for each data point.\n",
    "  \"\"\"\n",
    "  y_true = y_true.reshape(-1,1)\n",
    "#   y_pred = y_pred.reshape(-1,1)\n",
    "  loss = -0.1 * np.mean(y_true * y_pred, axis=0)  # Mean across features\n",
    "\n",
    "  # Calculate gradients (assuming y_true has the same shape as y_pred)\n",
    "  grad = -0.1 * y_true * np.mean(y_pred, axis=0)  # Mean across features\n",
    "\n",
    "  # Calculate hessians (assuming y_true has the same shape as y_pred)\n",
    "#   hess = 0.1 * np.mean(y_true**2, axis=0)  # Mean across features\n",
    "#   hess = np.repeat(hess, len(grad))\n",
    "  hess = 0.1 * np.square(y_true - np.mean(y_pred, axis=0))\n",
    "\n",
    "  return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regressor =xgb.XGBRegressor(\n",
    "            objective=custom_loss_function,\n",
    "            random_state=42,\n",
    "            booster='gbtree',\n",
    "            learning_rate=0.01,\n",
    "            max_depth=3,\n",
    "            min_child_weight=1,\n",
    "            gamma=0.2,\n",
    "            subsample=0.6\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=0.2, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None,\n",
       "             objective=&lt;function custom_loss_function at 0x2d105e680&gt;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=0.2, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None,\n",
       "             objective=&lt;function custom_loss_function at 0x2d105e680&gt;, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=0.2, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None,\n",
       "             objective=<function custom_loss_function at 0x2d105e680>, ...)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12194"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26716232, 0.26864362, 0.27096397, 0.2722605 , 0.37746617,\n",
       "       0.3789862 , 0.5666086 , 0.608553  , 0.7549487 , 0.76715744,\n",
       "       1.275924  , 1.2799871 ], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_pred = model_regressor.predict(X_test)\n",
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12194"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19.781813,\n",
       " 30.296232,\n",
       " 16.057196,\n",
       " 94.69511,\n",
       " 16.912243,\n",
       " 47.066338,\n",
       " 30.296232,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 174.85587,\n",
       " 16.912243,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 37.158813,\n",
       " 16.057196,\n",
       " 37.158813,\n",
       " 53.801575,\n",
       " 16.057196,\n",
       " 73.148544,\n",
       " 16.68122,\n",
       " 264.58716,\n",
       " 16.057196,\n",
       " 26.170399,\n",
       " 24.718222,\n",
       " 33.150127,\n",
       " 18.992563,\n",
       " 16.190746,\n",
       " 33.467533,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 18.992563,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 24.718222,\n",
       " 21.10041,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 22.835073,\n",
       " 30.296232,\n",
       " 22.835073,\n",
       " 29.391014,\n",
       " 16.057196,\n",
       " 26.170399,\n",
       " 18.115147,\n",
       " 17.41692,\n",
       " 18.992563,\n",
       " 110.248695,\n",
       " 26.170399,\n",
       " 16.057196,\n",
       " 30.296232,\n",
       " 110.248695,\n",
       " 18.992563,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 19.781813,\n",
       " 73.148544,\n",
       " 53.801575,\n",
       " 17.41692,\n",
       " 17.708601,\n",
       " 24.718222,\n",
       " 24.718222,\n",
       " 18.115147,\n",
       " 22.835073,\n",
       " 16.057196,\n",
       " 16.912243,\n",
       " 22.835073,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 17.708601,\n",
       " 22.835073,\n",
       " 16.057196,\n",
       " 16.190746,\n",
       " 17.41692,\n",
       " 53.801575,\n",
       " 30.296232,\n",
       " 24.718222,\n",
       " 24.718222,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 22.835073,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 19.781813,\n",
       " 19.781813,\n",
       " 24.718222,\n",
       " 35.698467,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 94.69511,\n",
       " 16.057196,\n",
       " 26.170399,\n",
       " 16.057196,\n",
       " 19.781813,\n",
       " 110.248695,\n",
       " 16.190746,\n",
       " 18.115147,\n",
       " 21.10041,\n",
       " 18.115147,\n",
       " 22.835073,\n",
       " 22.835073,\n",
       " 30.296232,\n",
       " 85.137024,\n",
       " 53.801575,\n",
       " 26.170399,\n",
       " 16.057196,\n",
       " 16.912243,\n",
       " 29.391014,\n",
       " 53.801575,\n",
       " 85.137024,\n",
       " 16.057196,\n",
       " 26.170399,\n",
       " 16.68122,\n",
       " 280.01813,\n",
       " 17.708601,\n",
       " 17.41692,\n",
       " 21.10041,\n",
       " 19.781813,\n",
       " 19.781813,\n",
       " 30.296232,\n",
       " 16.057196,\n",
       " 16.912243,\n",
       " 21.10041,\n",
       " 16.057196,\n",
       " 22.835073,\n",
       " 18.115147,\n",
       " 16.057196,\n",
       " 19.781813,\n",
       " 47.066338,\n",
       " 110.54747,\n",
       " 16.68122,\n",
       " 16.912243,\n",
       " 29.391014,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 45.60599,\n",
       " 33.150127,\n",
       " 16.057196,\n",
       " 73.148544,\n",
       " 16.057196,\n",
       " 16.68122,\n",
       " 21.10041,\n",
       " 45.60599,\n",
       " 18.992563,\n",
       " 19.781813,\n",
       " 57.645046,\n",
       " 16.057196,\n",
       " 18.115147,\n",
       " 18.992563,\n",
       " 16.057196,\n",
       " 53.801575,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 21.10041,\n",
       " 26.170399,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 17.708601,\n",
       " 18.115147,\n",
       " 16.190746,\n",
       " 17.41692,\n",
       " 16.057196,\n",
       " 21.10041,\n",
       " 16.68122,\n",
       " 16.057196,\n",
       " 73.148544,\n",
       " 16.912243,\n",
       " 16.68122,\n",
       " 16.190746,\n",
       " 17.41692,\n",
       " 22.835073,\n",
       " 19.781813,\n",
       " 18.115147,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 17.41692,\n",
       " 30.296232,\n",
       " 30.296232,\n",
       " 16.057196,\n",
       " 22.835073,\n",
       " 53.801575,\n",
       " 16.057196,\n",
       " 26.170399,\n",
       " 16.057196,\n",
       " 22.835073,\n",
       " 16.057196,\n",
       " 33.467533,\n",
       " 22.835073,\n",
       " 16.057196,\n",
       " 19.781813,\n",
       " 19.781813,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 26.170399,\n",
       " 45.60599,\n",
       " 16.057196,\n",
       " 21.10041,\n",
       " 16.057196,\n",
       " 29.391014,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 84.28522,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 22.835073,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.190746,\n",
       " 18.992563,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 24.718222,\n",
       " 264.58716,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 21.10041,\n",
       " 16.68122,\n",
       " 33.467533,\n",
       " 16.190746,\n",
       " 16.68122,\n",
       " 47.066338,\n",
       " 16.057196,\n",
       " 16.190746,\n",
       " 16.057196,\n",
       " 16.68122,\n",
       " 16.057196,\n",
       " 18.115147,\n",
       " 16.190746,\n",
       " 16.057196,\n",
       " 26.170399,\n",
       " 94.69511,\n",
       " 85.137024,\n",
       " 47.066338,\n",
       " 45.60599,\n",
       " 16.057196,\n",
       " 29.391014,\n",
       " 53.801575,\n",
       " 16.057196,\n",
       " 16.190746,\n",
       " 173.64139,\n",
       " 19.781813,\n",
       " 309.14438,\n",
       " 16.057196,\n",
       " 16.190746,\n",
       " 17.41692,\n",
       " 35.698467,\n",
       " 16.68122,\n",
       " 280.01813,\n",
       " 16.057196,\n",
       " 22.835073,\n",
       " 16.057196,\n",
       " 16.912243,\n",
       " 24.718222,\n",
       " 21.10041,\n",
       " 16.057196,\n",
       " 18.115147,\n",
       " 16.057196,\n",
       " 22.835073,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 18.992563,\n",
       " 16.057196,\n",
       " 21.10041,\n",
       " 19.781813,\n",
       " 16.057196,\n",
       " 17.41692,\n",
       " 16.912243,\n",
       " 16.912243,\n",
       " 16.190746,\n",
       " 16.057196,\n",
       " 73.148544,\n",
       " 21.10041,\n",
       " 33.150127,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 19.781813,\n",
       " 73.148544,\n",
       " 16.057196,\n",
       " 26.170399,\n",
       " 16.057196,\n",
       " 18.115147,\n",
       " 73.148544,\n",
       " 18.115147,\n",
       " 21.10041,\n",
       " 30.296232,\n",
       " 16.057196,\n",
       " 17.41692,\n",
       " 16.057196,\n",
       " 45.60599,\n",
       " 18.992563,\n",
       " 16.057196,\n",
       " 53.801575,\n",
       " 18.992563,\n",
       " 16.057196,\n",
       " 30.296232,\n",
       " 17.41692,\n",
       " 37.158813,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.190746,\n",
       " 16.057196,\n",
       " 29.391014,\n",
       " 16.057196,\n",
       " 24.718222,\n",
       " 26.170399,\n",
       " 85.137024,\n",
       " 174.39873,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 18.115147,\n",
       " 45.60599,\n",
       " 16.057196,\n",
       " 85.137024,\n",
       " 201.79063,\n",
       " 29.391014,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 110.54747,\n",
       " 24.718222,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.912243,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 18.115147,\n",
       " 371.91226,\n",
       " 16.057196,\n",
       " 45.60599,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 494.86484,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 33.150127,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 73.148544,\n",
       " 17.708601,\n",
       " 24.718222,\n",
       " 21.10041,\n",
       " 22.835073,\n",
       " 16.057196,\n",
       " 21.10041,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 18.992563,\n",
       " 16.057196,\n",
       " 16.68122,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 17.708601,\n",
       " 17.41692,\n",
       " 33.150127,\n",
       " 24.718222,\n",
       " 94.69511,\n",
       " 110.54747,\n",
       " 110.248695,\n",
       " 16.057196,\n",
       " 16.190746,\n",
       " 16.057196,\n",
       " 22.835073,\n",
       " 16.68122,\n",
       " 16.057196,\n",
       " 18.115147,\n",
       " 17.708601,\n",
       " 17.41692,\n",
       " 24.718222,\n",
       " 33.467533,\n",
       " 16.057196,\n",
       " 16.68122,\n",
       " 85.137024,\n",
       " 45.60599,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 22.835073,\n",
       " 33.150127,\n",
       " 73.148544,\n",
       " 26.170399,\n",
       " 16.190746,\n",
       " 22.835073,\n",
       " 24.718222,\n",
       " 16.057196,\n",
       " 16.68122,\n",
       " 16.057196,\n",
       " 22.835073,\n",
       " 18.115147,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 26.170399,\n",
       " 16.057196,\n",
       " 152.6556,\n",
       " 30.296232,\n",
       " 33.150127,\n",
       " 33.467533,\n",
       " 18.992563,\n",
       " 17.41692,\n",
       " 16.057196,\n",
       " 35.698467,\n",
       " 18.115147,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 29.391014,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 18.992563,\n",
       " 35.698467,\n",
       " 266.07565,\n",
       " 22.835073,\n",
       " 21.10041,\n",
       " 18.115147,\n",
       " 16.057196,\n",
       " 188.98932,\n",
       " 18.115147,\n",
       " 24.718222,\n",
       " 18.115147,\n",
       " 16.912243,\n",
       " 18.992563,\n",
       " 45.60599,\n",
       " 16.057196,\n",
       " 33.150127,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 110.248695,\n",
       " 17.708601,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 188.98932,\n",
       " 29.391014,\n",
       " 45.60599,\n",
       " 85.137024,\n",
       " 16.190746,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.68122,\n",
       " 16.057196,\n",
       " 24.718222,\n",
       " 29.391014,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 17.41692,\n",
       " 16.057196,\n",
       " 17.708601,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 21.10041,\n",
       " 16.057196,\n",
       " 57.645046,\n",
       " 33.150127,\n",
       " 16.057196,\n",
       " 33.150127,\n",
       " 16.057196,\n",
       " 110.248695,\n",
       " 33.150127,\n",
       " 175.1299,\n",
       " 16.057196,\n",
       " 26.170399,\n",
       " 17.708601,\n",
       " 24.718222,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 24.718222,\n",
       " 94.69511,\n",
       " 16.057196,\n",
       " 21.10041,\n",
       " 22.835073,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 85.137024,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 173.64139,\n",
       " 35.698467,\n",
       " 16.190746,\n",
       " 17.41692,\n",
       " 21.10041,\n",
       " 16.057196,\n",
       " 18.992563,\n",
       " 16.190746,\n",
       " 94.69511,\n",
       " 22.835073,\n",
       " 24.718222,\n",
       " 16.057196,\n",
       " 17.41692,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 18.992563,\n",
       " 16.68122,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 18.115147,\n",
       " 16.057196,\n",
       " 16.68122,\n",
       " 225.74918,\n",
       " 47.066338,\n",
       " 16.057196,\n",
       " 94.69511,\n",
       " 18.992563,\n",
       " 16.912243,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 33.150127,\n",
       " 16.057196,\n",
       " 17.708601,\n",
       " 24.718222,\n",
       " 16.057196,\n",
       " 17.41692,\n",
       " 24.718222,\n",
       " 22.835073,\n",
       " 16.057196,\n",
       " 18.115147,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 22.835073,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 19.781813,\n",
       " 33.150127,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 26.170399,\n",
       " 16.68122,\n",
       " 22.835073,\n",
       " 47.066338,\n",
       " 73.148544,\n",
       " 22.835073,\n",
       " 16.057196,\n",
       " 21.10041,\n",
       " 16.68122,\n",
       " 16.057196,\n",
       " 45.60599,\n",
       " 16.057196,\n",
       " 16.912243,\n",
       " 26.170399,\n",
       " 26.170399,\n",
       " 16.057196,\n",
       " 17.708601,\n",
       " 17.41692,\n",
       " 16.912243,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 26.170399,\n",
       " 26.170399,\n",
       " 16.190746,\n",
       " 21.10041,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 22.835073,\n",
       " 16.057196,\n",
       " 21.10041,\n",
       " 94.69511,\n",
       " 33.150127,\n",
       " 24.718222,\n",
       " 73.148544,\n",
       " 53.801575,\n",
       " 16.057196,\n",
       " 24.718222,\n",
       " 21.10041,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.68122,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.912243,\n",
       " 33.467533,\n",
       " 281.5066,\n",
       " 18.115147,\n",
       " 16.057196,\n",
       " 110.54747,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 17.708601,\n",
       " 265.80164,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 17.41692,\n",
       " 47.066338,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 21.10041,\n",
       " 35.698467,\n",
       " 16.190746,\n",
       " 47.066338,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 22.835073,\n",
       " 18.992563,\n",
       " 21.10041,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 45.60599,\n",
       " 73.148544,\n",
       " 45.60599,\n",
       " 33.467533,\n",
       " 18.115147,\n",
       " 24.718222,\n",
       " 19.781813,\n",
       " 53.801575,\n",
       " 16.057196,\n",
       " 18.992563,\n",
       " 24.718222,\n",
       " 45.60599,\n",
       " 19.781813,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 47.066338,\n",
       " 29.391014,\n",
       " 30.296232,\n",
       " 110.54747,\n",
       " 16.057196,\n",
       " 45.60599,\n",
       " 33.150127,\n",
       " 16.057196,\n",
       " 29.391014,\n",
       " 30.296232,\n",
       " 24.718222,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 33.150127,\n",
       " 16.057196,\n",
       " 26.170399,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 18.992563,\n",
       " 17.41692,\n",
       " 16.057196,\n",
       " 33.467533,\n",
       " 18.115147,\n",
       " 16.057196,\n",
       " 18.992563,\n",
       " 188.98932,\n",
       " 17.708601,\n",
       " 18.115147,\n",
       " 37.158813,\n",
       " 16.68122,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 45.60599,\n",
       " 16.190746,\n",
       " 18.992563,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 21.10041,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 22.835073,\n",
       " 45.60599,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 30.296232,\n",
       " 26.170399,\n",
       " 110.248695,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 26.170399,\n",
       " 94.69511,\n",
       " 16.057196,\n",
       " 16.190746,\n",
       " 53.801575,\n",
       " 33.467533,\n",
       " 16.68122,\n",
       " 33.467533,\n",
       " 110.248695,\n",
       " 16.057196,\n",
       " 16.190746,\n",
       " 29.391014,\n",
       " 16.057196,\n",
       " 16.68122,\n",
       " 24.718222,\n",
       " 47.066338,\n",
       " 18.992563,\n",
       " 18.992563,\n",
       " 16.057196,\n",
       " 18.115147,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 21.10041,\n",
       " 19.781813,\n",
       " 53.801575,\n",
       " 29.391014,\n",
       " 24.718222,\n",
       " 24.718222,\n",
       " 16.190746,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 18.992563,\n",
       " 29.391014,\n",
       " 24.718222,\n",
       " 18.115147,\n",
       " 18.992563,\n",
       " 16.057196,\n",
       " 18.115147,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 187.50081,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 18.992563,\n",
       " 26.170399,\n",
       " 18.992563,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 85.137024,\n",
       " 24.718222,\n",
       " 16.057196,\n",
       " 18.115147,\n",
       " 16.68122,\n",
       " 18.115147,\n",
       " 18.992563,\n",
       " 18.115147,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 53.801575,\n",
       " 16.057196,\n",
       " 17.708601,\n",
       " 16.057196,\n",
       " 19.781813,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 29.391014,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 30.296232,\n",
       " 16.057196,\n",
       " 47.066338,\n",
       " 110.248695,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 73.148544,\n",
       " 16.057196,\n",
       " 45.60599,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 17.708601,\n",
       " 16.057196,\n",
       " 29.391014,\n",
       " 16.057196,\n",
       " 17.41692,\n",
       " 73.148544,\n",
       " 16.057196,\n",
       " 30.296232,\n",
       " 21.10041,\n",
       " 45.60599,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 21.10041,\n",
       " 16.057196,\n",
       " 33.150127,\n",
       " 16.057196,\n",
       " 17.41692,\n",
       " 16.912243,\n",
       " 16.057196,\n",
       " 18.115147,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 17.708601,\n",
       " 30.296232,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 18.992563,\n",
       " 16.057196,\n",
       " 21.10041,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 26.170399,\n",
       " 19.781813,\n",
       " 17.708601,\n",
       " 16.057196,\n",
       " 22.835073,\n",
       " 22.835073,\n",
       " 17.41692,\n",
       " 33.467533,\n",
       " 16.057196,\n",
       " 35.698467,\n",
       " 57.645046,\n",
       " 16.057196,\n",
       " 18.992563,\n",
       " 18.115147,\n",
       " 16.057196,\n",
       " 22.835073,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.912243,\n",
       " 73.148544,\n",
       " 21.10041,\n",
       " 16.912243,\n",
       " 16.057196,\n",
       " 73.148544,\n",
       " 16.057196,\n",
       " 18.115147,\n",
       " 16.057196,\n",
       " 16.68122,\n",
       " 16.912243,\n",
       " 18.115147,\n",
       " 16.057196,\n",
       " 47.066338,\n",
       " 16.057196,\n",
       " 73.148544,\n",
       " 16.057196,\n",
       " 47.066338,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 29.391014,\n",
       " 73.148544,\n",
       " 16.68122,\n",
       " 16.912243,\n",
       " 16.68122,\n",
       " 21.10041,\n",
       " 37.158813,\n",
       " 18.115147,\n",
       " 24.718222,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 24.718222,\n",
       " 16.057196,\n",
       " 16.190746,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 24.718222,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 21.10041,\n",
       " 21.10041,\n",
       " 19.781813,\n",
       " 16.057196,\n",
       " 24.718222,\n",
       " 85.137024,\n",
       " 16.057196,\n",
       " 16.912243,\n",
       " 35.698467,\n",
       " 73.148544,\n",
       " 47.066338,\n",
       " 30.296232,\n",
       " 73.148544,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 22.835073,\n",
       " 16.057196,\n",
       " 33.150127,\n",
       " 24.718222,\n",
       " 16.190746,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 24.718222,\n",
       " 26.170399,\n",
       " 16.057196,\n",
       " 22.835073,\n",
       " 16.057196,\n",
       " 73.148544,\n",
       " 16.057196,\n",
       " 73.148544,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 24.718222,\n",
       " 16.057196,\n",
       " 24.718222,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 17.708601,\n",
       " 21.10041,\n",
       " 18.992563,\n",
       " 16.057196,\n",
       " 94.69511,\n",
       " 33.467533,\n",
       " 29.391014,\n",
       " 29.391014,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 53.801575,\n",
       " 21.10041,\n",
       " 16.057196,\n",
       " 18.992563,\n",
       " 17.41692,\n",
       " 21.10041,\n",
       " 16.057196,\n",
       " 29.391014,\n",
       " 30.296232,\n",
       " 18.992563,\n",
       " 16.057196,\n",
       " 30.296232,\n",
       " 16.057196,\n",
       " 18.992563,\n",
       " 16.057196,\n",
       " 19.781813,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 26.170399,\n",
       " 85.137024,\n",
       " 16.057196,\n",
       " 29.391014,\n",
       " 16.057196,\n",
       " 73.148544,\n",
       " 18.115147,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 18.992563,\n",
       " 16.68122,\n",
       " 37.158813,\n",
       " 30.296232,\n",
       " 19.781813,\n",
       " 22.835073,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 266.55893,\n",
       " 45.60599,\n",
       " 18.992563,\n",
       " 26.170399,\n",
       " 16.057196,\n",
       " 16.68122,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 18.115147,\n",
       " 33.150127,\n",
       " 37.158813,\n",
       " 35.698467,\n",
       " 16.057196,\n",
       " 33.150127,\n",
       " 21.10041,\n",
       " 22.835073,\n",
       " 21.10041,\n",
       " 16.057196,\n",
       " 17.708601,\n",
       " 45.60599,\n",
       " 45.60599,\n",
       " 18.992563,\n",
       " 16.68122,\n",
       " 18.992563,\n",
       " 18.992563,\n",
       " 17.41692,\n",
       " 29.391014,\n",
       " 29.391014,\n",
       " 17.708601,\n",
       " 18.992563,\n",
       " 21.10041,\n",
       " 16.190746,\n",
       " 22.835073,\n",
       " 33.150127,\n",
       " 16.057196,\n",
       " 30.296232,\n",
       " 16.057196,\n",
       " 22.835073,\n",
       " 18.992563,\n",
       " 73.148544,\n",
       " 16.057196,\n",
       " 16.057196,\n",
       " 19.781813,\n",
       " ...]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16.5,\n",
       " 24.767291033,\n",
       " 5.4,\n",
       " 90.0,\n",
       " 9.108286999581129,\n",
       " 75.0,\n",
       " 34.0,\n",
       " 7.568147213861849,\n",
       " 6.885064507,\n",
       " 267.6007225124438,\n",
       " 10.909007671896688,\n",
       " 6.231465666422573,\n",
       " 4.888689077180624,\n",
       " 36.0,\n",
       " 2.867075263,\n",
       " 60.367872506,\n",
       " 88.13115536217262,\n",
       " 5.4,\n",
       " 126.5303,\n",
       " 10.0,\n",
       " 330.0,\n",
       " 5.1,\n",
       " 25.0,\n",
       " 23.0,\n",
       " 45.8130323094636,\n",
       " 20.474401067,\n",
       " 9.491293245852289,\n",
       " 30.0,\n",
       " 8.534355028616993,\n",
       " 2.32,\n",
       " 8.10710447,\n",
       " 11.54,\n",
       " 7.750737656,\n",
       " 2.904650386891608,\n",
       " 19.42204,\n",
       " 14.26449497279376,\n",
       " 2.393072247,\n",
       " 4.9,\n",
       " 16.0,\n",
       " 50.0,\n",
       " 17.011553457,\n",
       " 31.36083769427079,\n",
       " 3.878235746478074,\n",
       " 26.0,\n",
       " 11.0,\n",
       " 10.85303484969566,\n",
       " 12.726299255,\n",
       " 170.0,\n",
       " 21.0,\n",
       " 3.198529910320405,\n",
       " 38.24050157,\n",
       " 112.12214258478544,\n",
       " 16.51228702331104,\n",
       " 2.930549049,\n",
       " 5.65878147,\n",
       " 16.5,\n",
       " 58.850090406,\n",
       " 80.0,\n",
       " 9.421818182829597,\n",
       " 11.09184048341951,\n",
       " 23.030318891,\n",
       " 29.0,\n",
       " 11.26413578959764,\n",
       " 18.5,\n",
       " 6.461530191,\n",
       " 11.7593235,\n",
       " 17.08934841281843,\n",
       " 1.8059678528553056,\n",
       " 6.0,\n",
       " 11.0,\n",
       " 22.0,\n",
       " 6.4,\n",
       " 8.93977465,\n",
       " 11.5,\n",
       " 68.02158711828034,\n",
       " 32.0,\n",
       " 19.62123184234388,\n",
       " 25.0,\n",
       " 1.35,\n",
       " 3.95,\n",
       " 20.0,\n",
       " 5.4,\n",
       " 4.944592168648752,\n",
       " 4.7,\n",
       " 13.034169141,\n",
       " 10.89088,\n",
       " 23.89118015969493,\n",
       " 35.066050001,\n",
       " 2.24704689381499,\n",
       " 8.864340765459637,\n",
       " 142.40290620645726,\n",
       " 3.65,\n",
       " 21.202785952808256,\n",
       " 4.2,\n",
       " 16.110112427,\n",
       " 196.04076398540403,\n",
       " 8.6,\n",
       " 12.914498624642192,\n",
       " 17.272324039,\n",
       " 10.69538834,\n",
       " 18.62603189,\n",
       " 20.14878650980281,\n",
       " 39.89948868,\n",
       " 97.178134465345,\n",
       " 60.0,\n",
       " 21.91308,\n",
       " 8.6,\n",
       " 9.74412417370426,\n",
       " 31.59995731145632,\n",
       " 54.36745091780218,\n",
       " 120.0,\n",
       " 4.151124825667939,\n",
       " 20.0,\n",
       " 11.949775075160431,\n",
       " 284.53323606230776,\n",
       " 11.5,\n",
       " 11.0,\n",
       " 17.7963299913297,\n",
       " 12.711394954811697,\n",
       " 15.97334238,\n",
       " 32.048659412539564,\n",
       " 3.3268506798136928,\n",
       " 10.80747132,\n",
       " 15.32369579,\n",
       " 7.4,\n",
       " 18.0,\n",
       " 12.0,\n",
       " 7.974221479663357,\n",
       " 12.570056084,\n",
       " 62.16750839212865,\n",
       " 143.47579364646222,\n",
       " 9.0,\n",
       " 10.5,\n",
       " 24.6448922,\n",
       " 5.3840668878019295,\n",
       " 3.363247085294315,\n",
       " 51.35415284611284,\n",
       " 38.02130168068224,\n",
       " 7.6,\n",
       " 54.63629428816087,\n",
       " 4.41532800665278,\n",
       " 9.140709714269976,\n",
       " 17.62455292650266,\n",
       " 64.764834008,\n",
       " 12.802135106350862,\n",
       " 15.077078046242244,\n",
       " 70.49866152650847,\n",
       " 8.6,\n",
       " 11.5,\n",
       " 16.0,\n",
       " 2.22,\n",
       " 66.88244241,\n",
       " 6.2,\n",
       " 4.27391133,\n",
       " 15.5,\n",
       " 25.0,\n",
       " 4.611908809231245,\n",
       " 8.63092047467217,\n",
       " 11.26426949848432,\n",
       " 14.5,\n",
       " 8.4,\n",
       " 11.5,\n",
       " 7.109195110282744,\n",
       " 15.101538004255447,\n",
       " 8.482956597,\n",
       " 6.2,\n",
       " 78.59322652115486,\n",
       " 9.2,\n",
       " 9.8,\n",
       " 8.0,\n",
       " 10.76683196,\n",
       " 16.5,\n",
       " 13.976394147152352,\n",
       " 11.744601620501964,\n",
       " 7.632206,\n",
       " 4.906514856104403,\n",
       " 5.6,\n",
       " 11.119225974780854,\n",
       " 29.0,\n",
       " 25.18090112,\n",
       " 5.216362166801141,\n",
       " 19.5,\n",
       " 46.0,\n",
       " 5.734996881201915,\n",
       " 23.5187583058285,\n",
       " 2.583047518,\n",
       " 17.67614040024987,\n",
       " 3.21326999,\n",
       " 44.47262098359458,\n",
       " 17.458112152572728,\n",
       " 6.8,\n",
       " 17.824774191298054,\n",
       " 15.0,\n",
       " 3.35,\n",
       " 6.2,\n",
       " 3.174748930861278,\n",
       " 2.7811214524598835,\n",
       " 28.559392671772216,\n",
       " 33.095598551,\n",
       " 3.2142609025835367,\n",
       " 20.0,\n",
       " 6.58917914,\n",
       " 20.282153895486108,\n",
       " 4.019339962229697,\n",
       " 6.850377534,\n",
       " 61.93197904185567,\n",
       " 5.215459115809826,\n",
       " 8.0,\n",
       " 17.0,\n",
       " 7.934667129333721,\n",
       " 8.278480951871025,\n",
       " 8.6,\n",
       " 13.342962380342652,\n",
       " 3.847068737140217,\n",
       " 5.602697430227963,\n",
       " 21.46223789843599,\n",
       " 318.62732018311146,\n",
       " 2.776993325,\n",
       " 5.21368507,\n",
       " 2.849114642461206,\n",
       " 13.21391976974832,\n",
       " 10.0,\n",
       " 57.48496782810697,\n",
       " 8.8,\n",
       " 9.721393406432473,\n",
       " 55.84016307,\n",
       " 5.78254771,\n",
       " 8.6,\n",
       " 7.166957208703245,\n",
       " 8.4,\n",
       " 8.0,\n",
       " 12.5,\n",
       " 8.482281671648874,\n",
       " 6.544783518,\n",
       " 23.889551644,\n",
       " 103.8420893093565,\n",
       " 91.63177961515876,\n",
       " 38.66554463450535,\n",
       " 36.87217127954922,\n",
       " 4.8,\n",
       " 23.46513107445091,\n",
       " 46.46118320918156,\n",
       " 6.779782338628937,\n",
       " 8.6,\n",
       " 277.61923356123265,\n",
       " 15.2910601,\n",
       " 680.0995893746846,\n",
       " 6.457890613377968,\n",
       " 9.002263590435614,\n",
       " 12.84047082873993,\n",
       " 39.694130461293966,\n",
       " 9.347755515362875,\n",
       " 253.7236877197912,\n",
       " 6.8,\n",
       " 19.5,\n",
       " 2.1185166338206187,\n",
       " 9.00296677,\n",
       " 29.48937954742461,\n",
       " 17.5,\n",
       " 3.65,\n",
       " 13.366553835768054,\n",
       " 4.552320857618588,\n",
       " 17.179794743728017,\n",
       " 6.0906066058400965,\n",
       " 4.4,\n",
       " 7.816982604661753,\n",
       " 2.90075607,\n",
       " 12.5,\n",
       " 8.499343565411838,\n",
       " 15.5,\n",
       " 17.22255400854861,\n",
       " 6.3054144,\n",
       " 12.0,\n",
       " 9.50432875,\n",
       " 9.038236201367688,\n",
       " 8.8,\n",
       " 2.86,\n",
       " 100.0,\n",
       " 16.228364423419613,\n",
       " 43.50650521576287,\n",
       " 4.722217567184053,\n",
       " 6.2,\n",
       " 14.5,\n",
       " 100.0,\n",
       " 5.898662302100329,\n",
       " 23.0,\n",
       " 5.32401202,\n",
       " 10.861312207,\n",
       " 140.0,\n",
       " 10.790968393,\n",
       " 15.74223027426682,\n",
       " 31.297316605858143,\n",
       " 2.44,\n",
       " 13.0,\n",
       " 9.072940136542313,\n",
       " 42.0,\n",
       " 11.805785576637714,\n",
       " 4.551812482120512,\n",
       " 46.8119303148803,\n",
       " 13.370509669690186,\n",
       " 5.6,\n",
       " 24.278095924315863,\n",
       " 12.5,\n",
       " 40.0,\n",
       " 2.26,\n",
       " 1.5852498104720452,\n",
       " 5.341989952857367,\n",
       " 4.635852486841445,\n",
       " 8.6,\n",
       " 8.032278793432194,\n",
       " 20.581819136801315,\n",
       " 7.0,\n",
       " 25.71962402,\n",
       " 20.706364559442587,\n",
       " 119.99765427456936,\n",
       " 222.4359546914863,\n",
       " 3.69112479931855,\n",
       " 11.0,\n",
       " 3.2,\n",
       " 2.19416983023164,\n",
       " 12.023453765262389,\n",
       " 46.0,\n",
       " 7.0,\n",
       " 135.69977647438296,\n",
       " 907.9753522763052,\n",
       " 26.62201372782002,\n",
       " 7.8,\n",
       " 6.285417757165416,\n",
       " 277.2466826618825,\n",
       " 21.9832923257551,\n",
       " 7.538601527187776,\n",
       " 7.6,\n",
       " 9.2,\n",
       " 2.761983616,\n",
       " 8.837915837,\n",
       " 11.5,\n",
       " 1000.0,\n",
       " 3.90027401,\n",
       " 42.0,\n",
       " 2.4373216455450617,\n",
       " 3.92798422477792,\n",
       " 1000.0,\n",
       " 4.88516397,\n",
       " 5.010693193710685,\n",
       " 30.82016773,\n",
       " 6.2,\n",
       " 5.7,\n",
       " 3.3111277014138203,\n",
       " 5.8,\n",
       " 141.21868946532305,\n",
       " 12.0,\n",
       " 22.58478542619972,\n",
       " 13.5,\n",
       " 16.87348,\n",
       " 4.9,\n",
       " 19.5,\n",
       " 2.742765721,\n",
       " 3.188340551521779,\n",
       " 13.0,\n",
       " 2.830780566459198,\n",
       " 7.452448442204881,\n",
       " 5.648606661,\n",
       " 1.2920120072392334,\n",
       " 10.5,\n",
       " 12.191940794197729,\n",
       " 34.34831101322249,\n",
       " 18.877944329560957,\n",
       " 85.0,\n",
       " 120.0,\n",
       " 205.839301906,\n",
       " 7.6,\n",
       " 8.096501543350323,\n",
       " 6.789647549,\n",
       " 16.54473508,\n",
       " 9.4,\n",
       " 7.2,\n",
       " 10.55219416,\n",
       " 11.71306297,\n",
       " 11.5,\n",
       " 25.0,\n",
       " 37.19872476,\n",
       " 4.8,\n",
       " 10.0,\n",
       " 105.68770479740226,\n",
       " 46.62813698586047,\n",
       " 7.2,\n",
       " 8.340955020810068,\n",
       " 22.0,\n",
       " 30.2554005941472,\n",
       " 90.709815297,\n",
       " 21.0,\n",
       " 8.48118075,\n",
       " 17.869059636,\n",
       " 21.957615312319533,\n",
       " 3.500272462186276,\n",
       " 9.2,\n",
       " 6.4,\n",
       " 20.66032341,\n",
       " 11.431198224129762,\n",
       " 6.59849601552476,\n",
       " 4.471257824,\n",
       " 24.0,\n",
       " 5.3,\n",
       " 236.562676223,\n",
       " 28.0,\n",
       " 35.728163213,\n",
       " 42.0,\n",
       " 14.073070372398869,\n",
       " 13.214823590723388,\n",
       " 2.41539482,\n",
       " 33.801005686,\n",
       " 11.83453527261558,\n",
       " 1.3076635574587594,\n",
       " 4.1,\n",
       " 4.77334457,\n",
       " 29.0,\n",
       " 5.0,\n",
       " 8.79812665,\n",
       " 13.58304167,\n",
       " 36.0,\n",
       " 302.65811837675824,\n",
       " 19.788646814893813,\n",
       " 13.898256895486554,\n",
       " 13.05979931,\n",
       " 3.8,\n",
       " 496.876949028,\n",
       " 12.5119163,\n",
       " 22.0,\n",
       " 10.202277894462544,\n",
       " 10.527474622635635,\n",
       " 16.0,\n",
       " 46.279568306,\n",
       " 4.93851078,\n",
       " 39.94317021416627,\n",
       " 5.2565845882945,\n",
       " 4.5,\n",
       " 96.85672457437992,\n",
       " 10.124822136335148,\n",
       " 3.3,\n",
       " 3.80927835,\n",
       " 266.59303398940966,\n",
       " 42.0,\n",
       " 58.54639282,\n",
       " 154.7332797147049,\n",
       " 8.794235244884511,\n",
       " 5.93816241,\n",
       " 6.037483173680231,\n",
       " 9.871427357407956,\n",
       " 4.936581869317343,\n",
       " 26.0,\n",
       " 26.0,\n",
       " 4.312670451611631,\n",
       " 5.425560627,\n",
       " 3.6750241707699023,\n",
       " 3.8173974235722743,\n",
       " 6.0,\n",
       " 11.5,\n",
       " 4.431548362819012,\n",
       " 11.43054094,\n",
       " 5.286226331252694,\n",
       " 5.53400432,\n",
       " 5.7,\n",
       " 21.0,\n",
       " 7.0,\n",
       " 120.0,\n",
       " 27.8431003998204,\n",
       " 4.781197875600157,\n",
       " 40.26153016335565,\n",
       " 5.3,\n",
       " 154.88313600285113,\n",
       " 31.65835314987329,\n",
       " 391.91385845050775,\n",
       " 7.889153422241834,\n",
       " 27.769996007337987,\n",
       " 11.487597796412883,\n",
       " 31.72326435,\n",
       " 8.74851707,\n",
       " 6.298910067234529,\n",
       " 20.0,\n",
       " 98.15947608,\n",
       " 2.45189906,\n",
       " 17.0,\n",
       " 23.100318428120303,\n",
       " 4.59374787,\n",
       " 6.402374641219852,\n",
       " 124.12910703,\n",
       " 7.657938881662266,\n",
       " 5.3,\n",
       " 162.01133229864303,\n",
       " 41.5932,\n",
       " 8.775833258431351,\n",
       " 11.450763355567398,\n",
       " 16.01255462674075,\n",
       " 5.172875164844591,\n",
       " 12.4203480091344,\n",
       " 8.2,\n",
       " 113.012740010159,\n",
       " 17.808180884101894,\n",
       " 19.0,\n",
       " 8.2,\n",
       " 11.08948751532145,\n",
       " 7.8,\n",
       " 6.246474019868764,\n",
       " 4.2,\n",
       " 13.5,\n",
       " 9.55383934,\n",
       " 7.4,\n",
       " 5.938692157397973,\n",
       " 4.40856303,\n",
       " 4.1,\n",
       " 5.462316930248162,\n",
       " 13.782097806,\n",
       " 6.6,\n",
       " 8.6,\n",
       " 545.526331391595,\n",
       " 65.0,\n",
       " 4.4,\n",
       " 93.043271691,\n",
       " 17.09367142,\n",
       " 9.851697072,\n",
       " 6.6,\n",
       " 7.6,\n",
       " 35.15098578,\n",
       " 5.4,\n",
       " 16.5,\n",
       " 21.0,\n",
       " 3.752954021239909,\n",
       " 9.802725720424498,\n",
       " 24.0,\n",
       " 18.33454516,\n",
       " 6.273002626163457,\n",
       " 12.792717157,\n",
       " 7.66078668,\n",
       " 7.2,\n",
       " 17.733699922,\n",
       " 3.538145007156085,\n",
       " 3.825105445281187,\n",
       " 16.0,\n",
       " 34.0,\n",
       " 4.77183344,\n",
       " 3.033632034,\n",
       " 32.11573725,\n",
       " 9.46844879,\n",
       " 21.0,\n",
       " 61.6143159713382,\n",
       " 166.9352506843023,\n",
       " 16.5,\n",
       " 8.850634032696547,\n",
       " 18.469329643826928,\n",
       " 9.532067980855643,\n",
       " 5.573398949570985,\n",
       " 57.89633933412841,\n",
       " 4.1,\n",
       " 10.91925047,\n",
       " 37.69574349,\n",
       " 25.291955457,\n",
       " 4.883495008,\n",
       " 8.8,\n",
       " 15.266086959489035,\n",
       " 9.0,\n",
       " 3.7,\n",
       " 5.044320389,\n",
       " 25.0,\n",
       " 25.928627687100427,\n",
       " 8.2,\n",
       " 14.5,\n",
       " 3.756533004147313,\n",
       " 2.799212216794122,\n",
       " 6.4,\n",
       " 16.9847075,\n",
       " 7.0,\n",
       " 16.10591364,\n",
       " 170.0,\n",
       " 40.09032071,\n",
       " 42.0,\n",
       " 70.0,\n",
       " 66.09007047754716,\n",
       " 6.511121533741388,\n",
       " 21.81451176877947,\n",
       " 13.08104019,\n",
       " 6.0224,\n",
       " 3.1241565786330647,\n",
       " 2.671157255,\n",
       " 9.78738844,\n",
       " 3.169841170617037,\n",
       " 6.317936739584222,\n",
       " 10.400274451,\n",
       " 38.327623929,\n",
       " 490.0,\n",
       " 12.0,\n",
       " 2.498802026102908,\n",
       " 110.0,\n",
       " 8.50118811354885,\n",
       " 3.45,\n",
       " 10.5,\n",
       " 500.0,\n",
       " 6.8,\n",
       " 5.1,\n",
       " 4.86810557182238,\n",
       " 13.5,\n",
       " 93.2610484293662,\n",
       " 3.21384854,\n",
       " 5.425322169,\n",
       " 3.7,\n",
       " 3.074471277,\n",
       " 18.53312993577856,\n",
       " 52.398136681498656,\n",
       " 9.2,\n",
       " 58.35052599545569,\n",
       " 3.173956327275994,\n",
       " 6.6,\n",
       " 21.105449519,\n",
       " 13.0,\n",
       " 16.0,\n",
       " 5.75456669,\n",
       " 7.0,\n",
       " 5.22055966,\n",
       " 8.6,\n",
       " 50.23466301642358,\n",
       " 141.752721882,\n",
       " 55.0,\n",
       " 70.0,\n",
       " 12.987567694814466,\n",
       " 20.012585441,\n",
       " 15.5,\n",
       " 46.67533310464999,\n",
       " 6.18200451366647,\n",
       " 14.5,\n",
       " 21.66658,\n",
       " 48.19763586,\n",
       " 15.5,\n",
       " 1.66,\n",
       " 4.56455377,\n",
       " 7.6,\n",
       " 4.92154686,\n",
       " 6.895582564673678,\n",
       " 5.240503509513112,\n",
       " 40.0,\n",
       " 32.67010789464695,\n",
       " 29.488854865043432,\n",
       " 192.31893347,\n",
       " 1.87244098,\n",
       " 57.18473659923532,\n",
       " 48.441588895,\n",
       " 5.928195832256888,\n",
       " 24.0,\n",
       " 36.0,\n",
       " 22.0,\n",
       " 7.2,\n",
       " 5.685743474618904,\n",
       " 34.04788915,\n",
       " 3.750549879,\n",
       " 20.0,\n",
       " 3.945754357594134,\n",
       " 7.483904821424404,\n",
       " 5.509716046797425,\n",
       " 6.41008593420236,\n",
       " 14.0,\n",
       " 11.0,\n",
       " 3.79141299,\n",
       " 80.0,\n",
       " 11.0,\n",
       " 7.4,\n",
       " 10.100163056368258,\n",
       " 201.97495847058863,\n",
       " 11.704040222705114,\n",
       " 12.0,\n",
       " 50.684475788748856,\n",
       " 9.8,\n",
       " 5.4,\n",
       " 2.75770547287674,\n",
       " 40.0,\n",
       " 9.828258416476306,\n",
       " 14.5,\n",
       " 4.2,\n",
       " 5.982387953,\n",
       " 16.300452593409798,\n",
       " 7.985284921812418,\n",
       " 6.169562483826377,\n",
       " 21.0,\n",
       " 47.277136070594295,\n",
       " 1.9218305067369648,\n",
       " 3.647110654209381,\n",
       " 27.219416458,\n",
       " 25.0,\n",
       " 135.7133651366172,\n",
       " 6.871393417221116,\n",
       " 3.2,\n",
       " 5.74,\n",
       " 7.4,\n",
       " 23.902146311506883,\n",
       " 150.80894261762813,\n",
       " 3.554953454337383,\n",
       " 9.2,\n",
       " 104.0766712,\n",
       " 39.3872820298931,\n",
       " 9.8,\n",
       " 46.0,\n",
       " 135.40923202450313,\n",
       " 1.743046518,\n",
       " 8.321542442825596,\n",
       " 38.0,\n",
       " 5.351942408469039,\n",
       " 9.755154156,\n",
       " 23.29166963,\n",
       " 110.0,\n",
       " 12.5496464,\n",
       " 11.044998642489242,\n",
       " 7.291912215,\n",
       " 12.0,\n",
       " 7.8,\n",
       " 2.6,\n",
       " 15.30218696,\n",
       " 13.13064741,\n",
       " 75.0,\n",
       " 31.42638329670532,\n",
       " 18.277066926,\n",
       " 24.65365492675395,\n",
       " 8.79780767,\n",
       " 9.06859380418348,\n",
       " 7.015460641,\n",
       " 14.992094160754352,\n",
       " 26.0,\n",
       " 18.40905452659829,\n",
       " 10.5,\n",
       " 17.0,\n",
       " 8.6,\n",
       " 12.179652827196056,\n",
       " 2.76,\n",
       " 4.49068293140437,\n",
       " 4.9,\n",
       " 285.9888779835658,\n",
       " 4.4,\n",
       " 6.7585336211665705,\n",
       " 4.6,\n",
       " 12.5,\n",
       " 23.929557406557137,\n",
       " 12.609528286,\n",
       " 6.4,\n",
       " 5.705533237210037,\n",
       " 7.852557057823889,\n",
       " 152.13510807635768,\n",
       " 27.3504872,\n",
       " 7.0,\n",
       " 13.374485880256064,\n",
       " 10.5,\n",
       " 10.316999279816844,\n",
       " 13.0,\n",
       " 12.5,\n",
       " 3.6,\n",
       " 6.96576239,\n",
       " 54.28958039178397,\n",
       " 6.0,\n",
       " 11.5,\n",
       " 5.388571707392137,\n",
       " 13.395703948,\n",
       " 3.55,\n",
       " 4.9,\n",
       " 23.0,\n",
       " 4.7,\n",
       " 6.0,\n",
       " 34.0,\n",
       " 8.4,\n",
       " 51.725381051272265,\n",
       " 221.6938317557395,\n",
       " 9.65849563,\n",
       " 2.040594278597159,\n",
       " 7.6,\n",
       " 152.6196400616287,\n",
       " 9.8,\n",
       " 42.0,\n",
       " 4.452085044734066,\n",
       " 8.204754663248895,\n",
       " 5.510027918339693,\n",
       " 6.2,\n",
       " 6.448627894531528,\n",
       " 12.314737699,\n",
       " 4.66862696,\n",
       " 23.011685536288944,\n",
       " 7.370321019435558,\n",
       " 11.14807140636782,\n",
       " 71.9959528866764,\n",
       " 4.214432135,\n",
       " 29.83406329,\n",
       " 16.698585646763455,\n",
       " 40.0,\n",
       " 4.24431474938162,\n",
       " 7.522579234,\n",
       " 2.42,\n",
       " 4.820226837,\n",
       " 13.150780146682305,\n",
       " 6.2,\n",
       " 32.997065027,\n",
       " 3.15,\n",
       " 10.346475742897198,\n",
       " 9.2,\n",
       " 8.64932801545037,\n",
       " 11.5,\n",
       " 2.04,\n",
       " 7.4,\n",
       " 11.541979386664458,\n",
       " 28.36750494,\n",
       " 6.4,\n",
       " 5.959223957795965,\n",
       " 13.0,\n",
       " 3.75,\n",
       " 15.48311495,\n",
       " 4.051861157285017,\n",
       " 3.2,\n",
       " 27.45433173744503,\n",
       " 14.5,\n",
       " 10.0,\n",
       " 5.289840761882476,\n",
       " 20.0,\n",
       " 18.829677269249217,\n",
       " 9.235372791,\n",
       " 28.967695717,\n",
       " 8.2,\n",
       " 42.56497746830805,\n",
       " 62.75491425,\n",
       " 5.056540385807057,\n",
       " 13.33069793,\n",
       " 13.77016627,\n",
       " 4.101924627765202,\n",
       " 20.46981417360345,\n",
       " 6.8240666984734135,\n",
       " 6.0,\n",
       " 7.6,\n",
       " 11.32146544310439,\n",
       " 62.68008089686744,\n",
       " 27.0,\n",
       " 10.32179192255871,\n",
       " 6.963655412747031,\n",
       " 118.7181216226192,\n",
       " 8.15091231187791,\n",
       " 11.0,\n",
       " 6.05421251,\n",
       " 9.516090581776371,\n",
       " 12.0,\n",
       " 12.632386750516035,\n",
       " 3.6,\n",
       " 75.0,\n",
       " 7.224777462171668,\n",
       " 68.63988088615355,\n",
       " 1.6228875998520604,\n",
       " 183.01044891622612,\n",
       " 7.94047,\n",
       " 8.08058608,\n",
       " 4.006864358249125,\n",
       " 8.0,\n",
       " 27.85949045612433,\n",
       " 75.0,\n",
       " 10.113757412759805,\n",
       " 11.58827604,\n",
       " 9.21091270757775,\n",
       " 17.635677037592448,\n",
       " 39.10662,\n",
       " 12.387834151693069,\n",
       " 23.247099919,\n",
       " 5.20452419,\n",
       " 4.9,\n",
       " 19.185327025,\n",
       " 3.106796396795552,\n",
       " 8.33196880042258,\n",
       " 6.271406796258816,\n",
       " 6.74897163,\n",
       " 7.406614100736043,\n",
       " 7.6525252,\n",
       " 18.66401146672025,\n",
       " 8.4,\n",
       " 4.70265683923528,\n",
       " 14.265150118,\n",
       " 14.123683312177024,\n",
       " 12.818639430845211,\n",
       " 8.08498883,\n",
       " 24.30609275,\n",
       " 66.2514855034975,\n",
       " 8.04486762,\n",
       " 11.5,\n",
       " 33.423205227722065,\n",
       " 68.311069145,\n",
       " 71.295884339,\n",
       " 30.0,\n",
       " 77.09057860230419,\n",
       " 4.327710508,\n",
       " 2.436687649,\n",
       " 17.499975110234473,\n",
       " 5.4,\n",
       " 56.61626247069059,\n",
       " 20.730361143214985,\n",
       " 9.339885674844844,\n",
       " 3.128144237,\n",
       " 1.7943496735473468,\n",
       " 19.629190924,\n",
       " 26.260904528659303,\n",
       " 6.242975049106025,\n",
       " 19.537233875410173,\n",
       " 5.24909707,\n",
       " 79.9864523385212,\n",
       " 4.5898402553146855,\n",
       " 85.0,\n",
       " 3.18420813,\n",
       " 6.8,\n",
       " 25.158271466712467,\n",
       " 3.227685450565249,\n",
       " 21.57622923016403,\n",
       " 4.9,\n",
       " 2.945353353,\n",
       " 10.05605098,\n",
       " 16.06205436,\n",
       " 13.2739835505822,\n",
       " 5.791283274393654,\n",
       " 140.0,\n",
       " 38.15025971269878,\n",
       " 27.0,\n",
       " 38.49053034040873,\n",
       " 3.3,\n",
       " 1.31,\n",
       " 5.97937898,\n",
       " 5.766964242817918,\n",
       " 65.31773563756732,\n",
       " 14.0,\n",
       " 5.7,\n",
       " 14.24631154916169,\n",
       " 10.6386464,\n",
       " 15.438319738,\n",
       " 8.0,\n",
       " 25.619652585,\n",
       " 38.58617646048116,\n",
       " 12.449856054,\n",
       " 3.83882982567091,\n",
       " 34.53861272,\n",
       " 5.410967126897029,\n",
       " 11.31979503631628,\n",
       " 5.39066661085193,\n",
       " 12.8036320648481,\n",
       " 2.718480960308579,\n",
       " 3.45,\n",
       " 24.0,\n",
       " 105.52622894427977,\n",
       " 3.95872564,\n",
       " 40.0,\n",
       " 8.13964277,\n",
       " 45.03009115240872,\n",
       " 11.75207999,\n",
       " 7.6421719,\n",
       " 3.52587205,\n",
       " 5.0,\n",
       " 5.87584665,\n",
       " 15.538416574847052,\n",
       " 9.2,\n",
       " 50.0,\n",
       " 30.0,\n",
       " 15.5,\n",
       " 18.0,\n",
       " 3.0662883028328296,\n",
       " 6.6,\n",
       " 346.3657303011365,\n",
       " 65.80255357069895,\n",
       " 13.5,\n",
       " 18.69433365,\n",
       " 5.42844856,\n",
       " 10.199984708687984,\n",
       " 4.3,\n",
       " 4.4,\n",
       " 12.90588118637941,\n",
       " 30.0,\n",
       " 29.1655035972372,\n",
       " 47.44106868,\n",
       " 4.9,\n",
       " 44.47006819674745,\n",
       " 16.044611276346256,\n",
       " 18.5,\n",
       " 14.877019873,\n",
       " 4.3,\n",
       " 12.0,\n",
       " 48.31752313873779,\n",
       " 50.0,\n",
       " 11.252834796425486,\n",
       " 9.2,\n",
       " 12.674270000511177,\n",
       " 15.5,\n",
       " 9.757718086611131,\n",
       " 32.0,\n",
       " 20.236585834318976,\n",
       " 13.412888375379843,\n",
       " 12.0,\n",
       " 12.98106,\n",
       " 7.55849774979135,\n",
       " 18.17007633488567,\n",
       " 35.68002336,\n",
       " 3.45575893,\n",
       " 29.29968260025416,\n",
       " 2.510572028814182,\n",
       " 18.5,\n",
       " 13.523854434682647,\n",
       " 100.32177972447128,\n",
       " 7.560698653,\n",
       " 8.0,\n",
       " 12.5,\n",
       " ...]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m accuracy\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/which_horse/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/which_horse/lib/python3.10/site-packages/sklearn/metrics/_classification.py:213\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/which_horse/lib/python3.10/site-packages/sklearn/metrics/_classification.py:105\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# No metrics support \"multiclass-multioutput\" format\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    108\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n",
      "\u001b[0;31mValueError\u001b[0m: continuous is not supported"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(model, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.68410206, 0.66847014, 0.70612979, 0.69902897, 0.66795301]),\n",
       " 'score_time': array([0.01481509, 0.01441979, 0.01542807, 0.01741695, 0.01682115]),\n",
       " 'test_score': array([0.99933752, 0.99941546, 0.99922061, 0.99925958, 0.99925958])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'tree_method': ['exact', 'hist'],\n",
    "    'booster': ['gbtree', 'dart'],\n",
    "    'learning_rate' : [0.001, 0.01],\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_paramgrid = {\n",
    "    'booster': ['gbtree'],\n",
    "    'learning_rate': [0.01],\n",
    "    'max_depth': [3],\n",
    "    'min_child_weight': [1],\n",
    "    'gamma': [0],\n",
    "    'subsample': [0.6],\n",
    "    'colsample_bytree': [0.6]\n",
    "                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Gr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m xgb_regressor \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBRegressor(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m grid_search_regressor \u001b[38;5;241m=\u001b[39m \u001b[43mGr\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Gr' is not defined"
     ]
    }
   ],
   "source": [
    "xgb_regressor = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "grid_search_regressor = GridSearchCV(estimator=xgb_regressor, param_grid=regressor_paramgrid, cv=5, scoring=['accuracy', 'precision', 'recall'], n_jobs=-1, verbose=3)\n",
    "grid_search_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"es = EarlyStopping(\\n    monitor='val_accuracy',\\n    min_delta=0,\\n    patience=5,\\n    verbose=0,\\n    mode='auto',\\n    baseline=None,\\n    restore_best_weights=True,\\n    start_from_epoch=0\\n        )\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''es = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=0\n",
    "        )'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 2/5] END booster=gbtree, learning_rate=0.001, tree_method=hist; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time=   3.2s\n",
      "[CV 1/5] END booster=gbtree, learning_rate=0.001, tree_method=hist; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time=   3.4s\n",
      "[CV 3/5] END booster=gbtree, learning_rate=0.001, tree_method=hist; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time=   3.2s\n",
      "[CV 5/5] END booster=gbtree, learning_rate=0.001, tree_method=hist; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time=   3.2s\n",
      "[CV 4/5] END booster=gbtree, learning_rate=0.001, tree_method=hist; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time=   3.4s\n",
      "[CV 1/5] END booster=gbtree, learning_rate=0.01, tree_method=hist; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time=   3.0s\n",
      "[CV 2/5] END booster=gbtree, learning_rate=0.01, tree_method=hist; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time=   2.9s\n",
      "[CV 3/5] END booster=gbtree, learning_rate=0.01, tree_method=hist; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jubba/.pyenv/versions/3.10.6/envs/which_horse/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END booster=gbtree, learning_rate=0.01, tree_method=hist; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time=   3.0s\n",
      "[CV 5/5] END booster=gbtree, learning_rate=0.01, tree_method=hist; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time=   2.9s\n",
      "[CV 1/5] END booster=gbtree, learning_rate=0.01, tree_method=exact; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time=  51.8s\n",
      "[CV 2/5] END booster=gbtree, learning_rate=0.001, tree_method=exact; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time=  52.0s\n",
      "[CV 1/5] END booster=gbtree, learning_rate=0.001, tree_method=exact; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time=  52.2s\n",
      "[CV 4/5] END booster=gbtree, learning_rate=0.001, tree_method=exact; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time=  53.1s\n",
      "[CV 3/5] END booster=gbtree, learning_rate=0.001, tree_method=exact; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time=  53.2s\n",
      "[CV 5/5] END booster=gbtree, learning_rate=0.001, tree_method=exact; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time=  53.6s\n",
      "[CV 2/5] END booster=gbtree, learning_rate=0.01, tree_method=exact; accuracy: (test=1.000) precision: (test=1.000) recall: (test=0.999) total time=  50.4s\n",
      "[CV 3/5] END booster=gbtree, learning_rate=0.01, tree_method=exact; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time=  50.7s\n",
      "[CV 5/5] END booster=gbtree, learning_rate=0.01, tree_method=exact; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time=  51.0s\n",
      "[CV 4/5] END booster=gbtree, learning_rate=0.01, tree_method=exact; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time=  51.9s\n",
      "[CV 1/5] END booster=dart, learning_rate=0.001, tree_method=exact; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time= 2.0min\n",
      "[CV 5/5] END booster=dart, learning_rate=0.001, tree_method=exact; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time= 2.0min\n",
      "[CV 2/5] END booster=dart, learning_rate=0.001, tree_method=exact; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time= 2.0min\n",
      "[CV 1/5] END booster=dart, learning_rate=0.01, tree_method=exact; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time= 1.9min\n",
      "[CV 4/5] END booster=dart, learning_rate=0.001, tree_method=exact; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time= 2.0min\n",
      "[CV 3/5] END booster=dart, learning_rate=0.001, tree_method=exact; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time= 2.1min\n",
      "[CV 2/5] END booster=dart, learning_rate=0.01, tree_method=exact; accuracy: (test=1.000) precision: (test=1.000) recall: (test=0.999) total time= 1.9min\n",
      "[CV 3/5] END booster=dart, learning_rate=0.01, tree_method=exact; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time= 1.9min\n",
      "[CV 5/5] END booster=dart, learning_rate=0.01, tree_method=exact; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time= 2.0min\n",
      "[CV 4/5] END booster=dart, learning_rate=0.01, tree_method=exact; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time= 2.1min\n",
      "[CV 4/5] END booster=dart, learning_rate=0.001, tree_method=hist; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time= 7.1min\n",
      "[CV 2/5] END booster=dart, learning_rate=0.001, tree_method=hist; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time= 7.1min\n",
      "[CV 1/5] END booster=dart, learning_rate=0.001, tree_method=hist; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time= 7.1min\n",
      "[CV 5/5] END booster=dart, learning_rate=0.001, tree_method=hist; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time= 7.1min\n",
      "[CV 3/5] END booster=dart, learning_rate=0.001, tree_method=hist; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time= 7.1min\n",
      "[CV 1/5] END booster=dart, learning_rate=0.01, tree_method=hist; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time= 6.4min\n",
      "[CV 2/5] END booster=dart, learning_rate=0.01, tree_method=hist; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time= 6.4min\n",
      "[CV 3/5] END booster=dart, learning_rate=0.01, tree_method=hist; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time= 5.8min\n",
      "[CV 4/5] END booster=dart, learning_rate=0.01, tree_method=hist; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time= 5.5min\n",
      "[CV 5/5] END booster=dart, learning_rate=0.01, tree_method=hist; accuracy: (test=0.999) precision: (test=1.000) recall: (test=0.999) total time= 5.6min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     objective=&#x27;reg:logistic&#x27;, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;booster&#x27;: [&#x27;gbtree&#x27;, &#x27;dart&#x27;],\n",
       "                         &#x27;learning_rate&#x27;: [0.001, 0.01],\n",
       "                         &#x27;tree_method&#x27;: [&#x27;exact&#x27;, &#x27;hist&#x27;]},\n",
       "             refit=&#x27;precision&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;],\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     objective=&#x27;reg:logistic&#x27;, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;booster&#x27;: [&#x27;gbtree&#x27;, &#x27;dart&#x27;],\n",
       "                         &#x27;learning_rate&#x27;: [0.001, 0.01],\n",
       "                         &#x27;tree_method&#x27;: [&#x27;exact&#x27;, &#x27;hist&#x27;]},\n",
       "             refit=&#x27;precision&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;],\n",
       "             verbose=3)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;reg:logistic&#x27;, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;reg:logistic&#x27;, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     objective='reg:logistic', ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'booster': ['gbtree', 'dart'],\n",
       "                         'learning_rate': [0.001, 0.01],\n",
       "                         'tree_method': ['exact', 'hist']},\n",
       "             refit='precision', scoring=['accuracy', 'precision', 'recall'],\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier = xgb.XGBClassifier(objective='reg:logistic', random_state=42)\n",
    "grid_search = GridSearchCV(estimator=xgb_classifier, refit='precision', param_grid= param_grid, cv=5, scoring=['accuracy', 'precision', 'recall'], n_jobs=-1, verbose=3)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nparam_grid = {\\n    'tree_method': ['exact', 'approx', 'hist'],\\n    'booster': ['gbtree', 'dart'],\\n    'learning_rate' : [0.001, 0.01, 0.1],\\n    'colsample_bytree': [0.8, 0.9, 1.0],\\n    'n_estimators': [100, 150, 200],\\n    'subsample': [0.7, 0.75, 0.8]\\n            }\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "param_grid = {\n",
    "    'tree_method': ['exact', 'approx', 'hist'],\n",
    "    'booster': ['gbtree', 'dart'],\n",
    "    'learning_rate' : [0.001, 0.01, 0.1],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'subsample': [0.7, 0.75, 0.8]\n",
    "            }'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = f\"best_params {grid_search.best_params_}\"\n",
    "best_score = f\"best_score {grid_search.best_score_}\"\n",
    "cv_results = grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"best_params {'booster': 'gbtree', 'learning_rate': 0.01, 'tree_method': 'exact'}\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'best_score 0.9998984576342377'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 52.71016111,   3.18339038,  51.03286939,   2.83630962,\n",
       "        118.48912759, 426.11167603, 116.80519495, 354.89514737]),\n",
       " 'std_fit_time': array([ 0.63412491,  0.09645775,  0.59963032,  0.06502486,  2.58601708,\n",
       "         1.16071306,  2.58449758, 22.20054746]),\n",
       " 'mean_score_time': array([0.11805797, 0.09797516, 0.10538454, 0.09140058, 1.71106033,\n",
       "        1.342976  , 1.68586192, 0.83240185]),\n",
       " 'std_score_time': array([0.02676029, 0.00765873, 0.00309493, 0.01481831, 0.1046494 ,\n",
       "        0.11714216, 0.06817362, 0.04439406]),\n",
       " 'param_booster': masked_array(data=['gbtree', 'gbtree', 'gbtree', 'gbtree', 'dart', 'dart',\n",
       "                    'dart', 'dart'],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.001, 0.001, 0.01, 0.01, 0.001, 0.001, 0.01, 0.01],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_tree_method': masked_array(data=['exact', 'hist', 'exact', 'hist', 'exact', 'hist',\n",
       "                    'exact', 'hist'],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'booster': 'gbtree',\n",
       "   'learning_rate': 0.001,\n",
       "   'tree_method': 'exact'},\n",
       "  {'booster': 'gbtree', 'learning_rate': 0.001, 'tree_method': 'hist'},\n",
       "  {'booster': 'gbtree', 'learning_rate': 0.01, 'tree_method': 'exact'},\n",
       "  {'booster': 'gbtree', 'learning_rate': 0.01, 'tree_method': 'hist'},\n",
       "  {'booster': 'dart', 'learning_rate': 0.001, 'tree_method': 'exact'},\n",
       "  {'booster': 'dart', 'learning_rate': 0.001, 'tree_method': 'hist'},\n",
       "  {'booster': 'dart', 'learning_rate': 0.01, 'tree_method': 'exact'},\n",
       "  {'booster': 'dart', 'learning_rate': 0.01, 'tree_method': 'hist'}],\n",
       " 'split0_test_accuracy': array([0.99933752, 0.99925958, 0.99941546, 0.99939597, 0.99933752,\n",
       "        0.99925958, 0.99941546, 0.99939597]),\n",
       " 'split1_test_accuracy': array([0.99949339, 0.99939597, 0.99951288, 0.99941546, 0.99949339,\n",
       "        0.99939597, 0.99951288, 0.99941546]),\n",
       " 'split2_test_accuracy': array([0.99920112, 0.99908421, 0.99924009, 0.99922061, 0.99920112,\n",
       "        0.99908421, 0.99924009, 0.99922061]),\n",
       " 'split3_test_accuracy': array([0.99920112, 0.99918164, 0.99925958, 0.99924009, 0.99920112,\n",
       "        0.99918164, 0.99925958, 0.99924009]),\n",
       " 'split4_test_accuracy': array([0.99927906, 0.99914267, 0.99925958, 0.99916215, 0.99927906,\n",
       "        0.99914267, 0.99925958, 0.99916215]),\n",
       " 'mean_test_accuracy': array([0.99930244, 0.99921281, 0.99933752, 0.99928686, 0.99930244,\n",
       "        0.99921281, 0.99933752, 0.99928686]),\n",
       " 'std_test_accuracy': array([0.00010842, 0.00010786, 0.00010814, 0.00010057, 0.00010842,\n",
       "        0.00010786, 0.00010814, 0.00010057]),\n",
       " 'rank_test_accuracy': array([3, 7, 1, 5, 3, 7, 1, 5], dtype=int32),\n",
       " 'split0_test_precision': array([0.9996877 , 0.99972667, 0.99984382, 0.99988285, 0.9996877 ,\n",
       "        0.99972667, 0.99984382, 0.99988285]),\n",
       " 'split1_test_precision': array([0.99996095, 0.99988285, 1.        , 0.99996095, 0.99996095,\n",
       "        0.99988285, 1.        , 0.99996095]),\n",
       " 'split2_test_precision': array([0.99984376, 0.99964851, 0.99988282, 0.99992187, 0.99984376,\n",
       "        0.99964851, 0.99988282, 0.99992187]),\n",
       " 'split3_test_precision': array([0.99976567, 0.9998047 , 0.99988282, 0.99984377, 0.99976567,\n",
       "        0.9998047 , 0.99988282, 0.99984377]),\n",
       " 'split4_test_precision': array([0.99992188, 0.99972662, 0.99988283, 0.99972663, 0.99992188,\n",
       "        0.99972662, 0.99988283, 0.99972663]),\n",
       " 'mean_test_precision': array([0.99983599, 0.99975787, 0.99989846, 0.99986721, 0.99983599,\n",
       "        0.99975787, 0.99989846, 0.99986721]),\n",
       " 'std_test_precision': array([9.99894280e-05, 7.96554889e-05, 5.29702260e-05, 8.04140448e-05,\n",
       "        9.99894280e-05, 7.96554889e-05, 5.29702260e-05, 8.04140448e-05]),\n",
       " 'rank_test_precision': array([5, 7, 1, 3, 5, 7, 1, 3], dtype=int32),\n",
       " 'split0_test_recall': array([0.99898572, 0.99879067, 0.99898572, 0.9989077 , 0.99898572,\n",
       "        0.99879067, 0.99898572, 0.9989077 ]),\n",
       " 'split1_test_recall': array([0.99902473, 0.9989077 , 0.99902473, 0.99886869, 0.99902473,\n",
       "        0.9989077 , 0.99902473, 0.99886869]),\n",
       " 'split2_test_recall': array([0.9985566 , 0.99851759, 0.99859562, 0.99851759, 0.9985566 ,\n",
       "        0.99851759, 0.99859562, 0.99851759]),\n",
       " 'split3_test_recall': array([0.99863463, 0.9985566 , 0.99863463, 0.99863463, 0.99863463,\n",
       "        0.9985566 , 0.99863463, 0.99863463]),\n",
       " 'split4_test_recall': array([0.99863468, 0.99855666, 0.99863468, 0.99859567, 0.99863468,\n",
       "        0.99855666, 0.99863468, 0.99859567]),\n",
       " 'mean_test_recall': array([0.99876727, 0.99866585, 0.99877508, 0.99870486, 0.99876727,\n",
       "        0.99866585, 0.99877508, 0.99870486]),\n",
       " 'std_test_recall': array([0.00019676, 0.00015486, 0.00018886, 0.00015486, 0.00019676,\n",
       "        0.00015486, 0.00018886, 0.00015486]),\n",
       " 'rank_test_recall': array([3, 7, 1, 5, 3, 7, 1, 5], dtype=int32)}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 23.71115322,   1.64435973,  25.06086516,   1.42902131,\n",
      "        56.36529317, 259.8737062 ,  58.34771585, 223.33002462]), 'std_fit_time': array([ 0.96436945,  0.04567247,  0.3085668 ,  0.12016324,  1.75704057,\n",
      "        0.47261534,  1.12486954, 11.10155684]), 'mean_score_time': array([0.06157198, 0.06458688, 0.06287384, 0.06085525, 1.03406153,\n",
      "       0.71242743, 0.89523897, 0.46057835]), 'std_score_time': array([0.00931494, 0.00927424, 0.01264093, 0.00363337, 0.13719717,\n",
      "       0.08998408, 0.10421476, 0.01487708]), 'param_booster': masked_array(data=['gbtree', 'gbtree', 'gbtree', 'gbtree', 'dart', 'dart',\n",
      "                   'dart', 'dart'],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_learning_rate': masked_array(data=[0.001, 0.001, 0.01, 0.01, 0.001, 0.001, 0.01, 0.01],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_tree_method': masked_array(data=['exact', 'hist', 'exact', 'hist', 'exact', 'hist',\n",
      "                   'exact', 'hist'],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'booster': 'gbtree', 'learning_rate': 0.001, 'tree_method': 'exact'}, {'booster': 'gbtree', 'learning_rate': 0.001, 'tree_method': 'hist'}, {'booster': 'gbtree', 'learning_rate': 0.01, 'tree_method': 'exact'}, {'booster': 'gbtree', 'learning_rate': 0.01, 'tree_method': 'hist'}, {'booster': 'dart', 'learning_rate': 0.001, 'tree_method': 'exact'}, {'booster': 'dart', 'learning_rate': 0.001, 'tree_method': 'hist'}, {'booster': 'dart', 'learning_rate': 0.01, 'tree_method': 'exact'}, {'booster': 'dart', 'learning_rate': 0.01, 'tree_method': 'hist'}], 'split0_test_accuracy': array([0.88834885, 0.88834885, 0.99607032, 0.99610479, 0.88834885,\n",
      "       0.88834885, 0.99607032, 0.99610479]), 'split1_test_accuracy': array([0.88834885, 0.88834885, 0.99600138, 0.99600138, 0.88834885,\n",
      "       0.88834885, 0.99600138, 0.99600138]), 'split2_test_accuracy': array([0.88834885, 0.88834885, 0.99589797, 0.99607032, 0.88834885,\n",
      "       0.88834885, 0.99589797, 0.99607032]), 'split3_test_accuracy': array([0.88831437, 0.88831437, 0.99572561, 0.99572561, 0.88831437,\n",
      "       0.88831437, 0.99572561, 0.99572561]), 'split4_test_accuracy': array([0.888345  , 0.888345  , 0.99600124, 0.99610466, 0.888345  ,\n",
      "       0.888345  , 0.99600124, 0.99610466]), 'mean_test_accuracy': array([0.88834118, 0.88834118, 0.9959393 , 0.99600135, 0.88834118,\n",
      "       0.88834118, 0.9959393 , 0.99600135]), 'std_test_accuracy': array([1.34861001e-05, 1.34861001e-05, 1.20189820e-04, 1.42941226e-04,\n",
      "       1.34861001e-05, 1.34861001e-05, 1.20189820e-04, 1.42941226e-04]), 'rank_test_accuracy': array([5, 5, 3, 1, 5, 5, 3, 1], dtype=int32), 'split0_test_precision': array([0.        , 0.        , 0.97739077, 0.97768949, 0.        ,\n",
      "       0.        , 0.97739077, 0.97768949]), 'split1_test_precision': array([0.        , 0.        , 0.97476437, 0.97418767, 0.        ,\n",
      "       0.        , 0.97476437, 0.97418767]), 'split2_test_precision': array([0.        , 0.        , 0.97882136, 0.9791475 , 0.        ,\n",
      "       0.        , 0.97882136, 0.9791475 ]), 'split3_test_precision': array([0.        , 0.        , 0.97355623, 0.97298118, 0.        ,\n",
      "       0.        , 0.97355623, 0.97298118]), 'split4_test_precision': array([0.        , 0.        , 0.97592198, 0.976234  , 0.        ,\n",
      "       0.        , 0.97592198, 0.976234  ]), 'mean_test_precision': array([0.        , 0.        , 0.97609094, 0.97604797, 0.        ,\n",
      "       0.        , 0.97609094, 0.97604797]), 'std_test_precision': array([0.        , 0.        , 0.00186322, 0.00224509, 0.        ,\n",
      "       0.        , 0.00186322, 0.00224509]), 'rank_test_precision': array([5, 5, 1, 3, 5, 5, 1, 3], dtype=int32), 'split0_test_recall': array([0.        , 0.        , 0.98765051, 0.98765051, 0.        ,\n",
      "       0.        , 0.98765051, 0.98765051]), 'split1_test_recall': array([0.        , 0.        , 0.98981167, 0.99042914, 0.        ,\n",
      "       0.        , 0.98981167, 0.99042914]), 'split2_test_recall': array([0.        , 0.        , 0.98456314, 0.98579809, 0.        ,\n",
      "       0.        , 0.98456314, 0.98579809]), 'split3_test_recall': array([0.        , 0.        , 0.98858025, 0.98919753, 0.        ,\n",
      "       0.        , 0.98858025, 0.98919753]), 'split4_test_recall': array([0.        , 0.        , 0.98857672, 0.9891942 , 0.        ,\n",
      "       0.        , 0.98857672, 0.9891942 ]), 'mean_test_recall': array([0.        , 0.        , 0.98783646, 0.98845389, 0.        ,\n",
      "       0.        , 0.98783646, 0.98845389]), 'std_test_recall': array([0.        , 0.        , 0.00177493, 0.00159383, 0.        ,\n",
      "       0.        , 0.00177493, 0.00159383]), 'rank_test_recall': array([5, 5, 3, 1, 5, 5, 3, 1], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_booster', 'param_learning_rate', 'param_tree_method', 'params', 'split0_test_accuracy', 'split1_test_accuracy', 'split2_test_accuracy', 'split3_test_accuracy', 'split4_test_accuracy', 'mean_test_accuracy', 'std_test_accuracy', 'rank_test_accuracy', 'split0_test_precision', 'split1_test_precision', 'split2_test_precision', 'split3_test_precision', 'split4_test_precision', 'mean_test_precision', 'std_test_precision', 'rank_test_precision', 'split0_test_recall', 'split1_test_recall', 'split2_test_recall', 'split3_test_recall', 'split4_test_recall', 'mean_test_recall', 'std_test_recall', 'rank_test_recall'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99876727, 0.99866585, 0.99877508, 0.99870486, 0.99876727,\n",
       "       0.99866585, 0.99877508, 0.99870486])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['mean_test_recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "which_horse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
